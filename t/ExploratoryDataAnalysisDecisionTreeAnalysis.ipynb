{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Misc\n",
    "import datetime\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# EDA Tools\n",
    "import ppscore as pps #<! See https://github.com/8080labs/ppscore -> pip install git+https://github.com/8080labs/ppscore.git\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedGroupKFold, train_test_split\n",
    "\n",
    "# Ensemble Engines\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "from ipywidgets import interact, Dropdown, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FOLDER_NAME    = 'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet0'\n",
    "DATA_FILE_EXT       = 'csv'\n",
    "\n",
    "PROJECT_DIR_NAME = 'CyVers' #<! Royi: Anton, don't change it, it should be a team constant\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after / before `CyVers`\n",
    "\n",
    "# Feature extractors constants\n",
    "\n",
    "TRAIN_BY_TSX    = 1\n",
    "TRAIN_BY_FILES  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CyVers Packages\n",
    "from DataSetsAuxFun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "# Features Analysis\n",
    "numCrossValPps = 4\n",
    "\n",
    "# Training\n",
    "trainMode = TRAIN_BY_FILES\n",
    "testSetRatio = 1 / 3\n",
    "numKFolds = 3\n",
    "gridSearchScore = 'f1' #<! Use strings from `sklearn.metrics.get_scorer_names()`\n",
    "gridSearchScore = 'recall' #<! We need to have better PD\n",
    "\n",
    "# Amount USD Outlier threshold\n",
    "amountUsdOutlierThr = 1e9\n",
    "\n",
    "randomState = 42\n",
    "\n",
    "lSlctedFeaturesRaw    = ['Amount', 'Currency', 'Currency Type', 'Amount [USD]', 'Receiver Type', 'Gas Price', 'Gas Limit', 'Gas Used' ]#lSlctedFeaturesRaw    = ['Amount', 'Currency', 'Amount [USD]', 'Receiver Type']\n",
    "lSlctedFeaturesCalc   = [enumObj.name for enumObj in FeatureName if ((enumObj is not FeatureName.TIME_MAX) and (enumObj is not FeatureName.TIME_MIN))]\n",
    "lSlctdFeatures        = lSlctedFeaturesRaw + lSlctedFeaturesCalc\n",
    "lCatFeatures          = ['Currency', 'Currency Type', 'Receiver Type']#lCatFeatures          = ['Currency', 'Receiver Type']\n",
    "# lFeaturesRemove       = [FeatureName.TIME_MAX.name, FeatureName.TIME_MIN.name] #<! Auxiliary features to be removed before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "lCsvFile = ExtractCsvFiles(dataSetRotoDir, folderNamePattern = DATA_FOLDER_PATTERN)\n",
    "print(f'The number of file found: {len(lCsvFile)}')\n",
    "\n",
    "# dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "dfData, dAssetFile = LoadCsvFilesDf(lCsvFile, baseFoldePath = '')\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f\"The number of rows (Samples): {numRows}, The number of columns: {numCols}, number of unique sender id's: {dfData['Sender ID'].unique().shape}\")\n",
    "print(f'The data list of columns is: {dfData.columns} with {len(dfData.columns)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time data into Pandas format\n",
    "dfData['Transaction Time'] = pd.to_datetime(dfData['Transaction Time'], infer_datetime_format = 'True') #<! Stable time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by transaction date\n",
    "dfData.sort_values('Transaction Time', inplace = True)\n",
    "# dfData.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meet the data\n",
    "dfData.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about the Data Before Pre Processing\n",
    "\n",
    "1. See the labeled cases.\n",
    "2. Count the Labels data.\n",
    "3. Number of unique assets.\n",
    "4. Pandas' `info()` and `describe()`.\n",
    "\n",
    "After this phase, the data is _read only_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at attack cases\n",
    "dfData.loc[dfData['Label'] == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance of labels: Highly imbalanced data (As expected)\n",
    "dfData['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique `Sender ID` (Assets) we have.\n",
    "# It should match the number of files, if not, it either means we have duplications or teh same asset was attacked twice.\n",
    "len(dfData['Sender ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing\n",
    "\n",
    "1. Remove invalid data.\n",
    "2. Remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting invalid `Amount USD`\n",
    "\n",
    "dsInValidTrnsUsd = ((dfData['Amount [USD]'] == 0) | (dfData['Amount [USD]'].isna()) | (dfData['Amount [USD]'] == ''))\n",
    "\n",
    "print(f'Number of invalid `Amount [USD]`: {dsInValidTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid data\n",
    "dfData.drop(dfData.index[dsInValidTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Outliers in the `Amount [USD]`\n",
    "\n",
    "dsOutlierTrnsUsd = ((dfData['Amount [USD]'] >= amountUsdOutlierThr) | (dfData['Amount [USD]'] <= 0))\n",
    "\n",
    "print(f'Number of outliers `Amount [USD]`: {dsOutlierTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "dfData.drop(dfData.index[dsOutlierTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on this is the data to work with\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the Data\n",
    "\n",
    "Basic infomration about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Information\n",
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Data Description\n",
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each hacker attacked\n",
    "dsAttacksAsset = dfData[dfData['Label'] == 1]['Receiver ID'].value_counts()\n",
    "\n",
    "print(f'There are {dsAttacksAsset.shape[0]} Attackers')\n",
    "print(dsAttacksAsset.head(len(dsAttacksAsset))) #<! Last ones should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each asset was attacked?\n",
    "dsSenderCount = dfData[dfData['Label'] == 1]['Sender ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different assets each attacker attacked? How many times per asset?\n",
    "dsAttacksIdAttacker = dfData[dfData['Label'] == 1].groupby(['Receiver ID', 'Sender ID'])['Transaction ID'].count().reset_index(name = 'Number of Attacks')  \n",
    "dsAttacksIdAttacker.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Pandas Extension (Don't change the Index from now on!)\n",
    "numGrps = dfData.GrpBySender.numGrps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SASA vs. SAMA Cases\n",
    "\n",
    "Definitions:\n",
    "\n",
    " * SASA:\n",
    " * SAMA:\n",
    "\n",
    "**Remark**: Move to:\n",
    "\n",
    "SASASW - Single Asset, Single   Attacks, Single   Wallets  \n",
    "SAMASW - Single Asset, Multiple Attacks, Single   Wallets (SAMA)  \n",
    "SAMAMW - Single Asset, Multiple Attacks, Multiple Wallets (SAMA)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Attack Type\n",
    "# !!! The function `CalcAttackType()` uses the Pandas extension, hence it should be initialized before!\n",
    "dsAttackType, dfAttackType = CalcAttackType(dfData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section adds features and engineers them.  \n",
    "Most features work on the `Sender ID` group.\n",
    "\n",
    "#### Amount Based Features:\n",
    "\n",
    "1. The STD of the user vs the average STD of all other users of the asset.\n",
    "2. The Median of the user vs the average STD of all other users of the asset.\n",
    "3. \n",
    "\n",
    "#### Date Based Features\n",
    "\n",
    "1. The day of the week.\n",
    "2. Weekend.\n",
    "3. Hour of the day.\n",
    "4. STD fo the time difference of the user vs. the avergae of all other users.\n",
    "5. Median fo the time difference of the user vs. the avergae of all other users.\n",
    "\n",
    "**Remark**: For wallets with a lot of activity we need to analyze the \"activity hours\" and profile it.\n",
    "\n",
    "\n",
    "The features are:\n",
    "\n",
    " 1. Day of the Week.\n",
    "\n",
    "Remarks:\n",
    "\n",
    " *  Features x-y are time / frequency related.\n",
    " *  Features z-t are trasnaction realted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process\n",
    "\n",
    "dfGbs = dfData.GrpBySender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features per Asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based\n",
    "\n",
    "sum_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s          = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s        = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s         = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "coint_c         = dfGbs.AggBySender(colName = dfGbs.currencyColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_COIN_TYPE)\n",
    "receiver_type_c = dfGbs.AggBySender(colName = dfGbs.receiverTypeColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_RECEIVER_TYPE)\n",
    "\n",
    "gas_pr_mean     = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_lim_mean    = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_used_mean   = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_pr_std      = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_lim_std     = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_used_std    = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_pr_med      = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_lim_med     = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_used_med    = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "\n",
    "\n",
    "dfData[FeatureName.AMOUNT_SUM_ASSET.name]          = sum_s\n",
    "dfData[FeatureName.AMOUNT_MEAN_ASSET.name]         = mean_s\n",
    "dfData[FeatureName.AMOUNT_STD_ASSET.name]          = std_s\n",
    "dfData[FeatureName.AMOUNT_VAR_ASSET.name]          = var_s\n",
    "dfData[FeatureName.AMOUNT_MEDIAN_ASSET.name]       = median_s\n",
    "dfData[FeatureName.AMOUNT_MIN_ASSET.name]          = min_s\n",
    "dfData[FeatureName.AMOUNT_MAX_ASSET.name]          = max_s\n",
    "dfData[FeatureName.TSX_COUNT_ASSET.name]           = count_s\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_ASSET.name]     = coint_c\n",
    "dfData[FeatureName.RECEIVER_TYPE_COUNT_ASSET.name] = receiver_type_c\n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_MEAN_ASSET.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_PRICE_STD_ASSET.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_PRICE_MEDIAN_ASSET.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_LIMIT_MEAN_ASSET.name] = gas_lim_mean\n",
    "dfData[FeatureName.GAS_LIMIT_STD_ASSET.name] = gas_lim_std\n",
    "dfData[FeatureName.GAS_LIMIT_MEDIAN_ASSET.name] = gas_lim_med\n",
    "\n",
    "dfData[FeatureName.GAS_USED_MEAN_ASSET.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_USED_STD_ASSET.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_USED_MEDIAN_ASSET.name] = gas_pr_med\n",
    "\n",
    "#COIN_TYPE_COUNT_USR                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "td_mean_s   = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_ASSET.name]   = td_mean_s\n",
    "dfData[FeatureName.TIME_DIFF_STD_ASSET.name]    = td_std_s\n",
    "dfData[FeatureName.TIME_DIFF_MEDIAN_ASSET.name] = td_median_s\n",
    "dfData[FeatureName.TIME_DIFF_MIN_ASSET.name]    = td_min_s\n",
    "dfData[FeatureName.TIME_DIFF_MAX_ASSET.name]    = td_max_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based (User)\n",
    "\n",
    "sum_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s          = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s        = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s         = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "coin_c          = dfGbs.AggByReceiver(colName = dfGbs.currencyColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_COIN_TYPE)\n",
    "receiver_type_c = dfGbs.AggByReceiver(colName = dfGbs.receiverTypeColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_RECEIVER_TYPE) #<! Royi: We need to check why is it so important?!?!\n",
    "\n",
    "gas_pr_mean     = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_lim_mean    = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_used_mean   = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "\n",
    "gas_pr_std      = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_lim_std     = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_used_std    = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "\n",
    "gas_pr_med      = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_lim_med     = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_used_med    = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "\n",
    "gas_pr_quant    = dfGbs.dfSubGrpByRec[dfGbs.gasPriceColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "gas_lim_quant   = dfGbs.dfSubGrpByRec[dfGbs.gasLimitColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "gas_used_quant  = dfGbs.dfSubGrpByRec[dfGbs.gasUsedColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "\n",
    "\n",
    "dfData[FeatureName.AMOUNT_SUM_USR.name]          = sum_s\n",
    "dfData[FeatureName.AMOUNT_MEAN_USR.name]         = mean_s\n",
    "dfData[FeatureName.AMOUNT_STD_USR.name]          = std_s\n",
    "dfData[FeatureName.AMOUNT_VAR_USR.name]          = var_s\n",
    "dfData[FeatureName.AMOUNT_MEDIAN_USR.name]       = median_s\n",
    "dfData[FeatureName.AMOUNT_MIN_USR.name]          = min_s\n",
    "dfData[FeatureName.AMOUNT_MAX_USR.name]          = max_s\n",
    "dfData[FeatureName.TSX_COUNT_USR.name]           = count_s\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_USR.name]     = coin_c\n",
    "dfData[FeatureName.RECEIVER_TYPE_COUNT_USR.name] = receiver_type_c    \n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_MEAN_USR.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_PRICE_STD_USR.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_PRICE_MEDIAN_USR.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_LIMIT_MEAN_USR.name] = gas_lim_mean\n",
    "dfData[FeatureName.GAS_LIMIT_STD_USR.name] = gas_lim_std\n",
    "dfData[FeatureName.GAS_LIMIT_MEDIAN_USR.name] = gas_lim_med\n",
    "\n",
    "dfData[FeatureName.GAS_USED_MEAN_USR.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_USED_STD_USR.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_USED_MEDIAN_USR.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_QUANTILE_USR.name] = gas_pr_quant\n",
    "dfData[FeatureName.GAS_LIMIT_QUANTILE_USR.name] = gas_lim_quant\n",
    "dfData[FeatureName.GAS_USED_QUANTILE_USR.name] = gas_used_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based (User)\n",
    "\n",
    "td_mean_s   = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_USR.name]   = td_mean_s\n",
    "dfData[FeatureName.TIME_DIFF_STD_USR.name]    = td_std_s\n",
    "dfData[FeatureName.TIME_DIFF_MEDIAN_USR.name] = td_median_s\n",
    "dfData[FeatureName.TIME_DIFF_MIN_USR.name]    = td_min_s\n",
    "dfData[FeatureName.TIME_DIFF_MAX_USR.name]    = td_max_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Transaction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "dfData[FeatureName.TIME_HOUR.name]    = dfGbs.GetTimeVals(periodTimeType = PeriodTimeType.HOUR_DAY)\n",
    "dfData[FeatureName.TIME_WEEKDAY.name] = dfGbs.GetTimeVals(periodTimeType = PeriodTimeType.DAY_WEEK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio Based Features\n",
    "\n",
    "dfData[FeatureName.AMOUNT_MEAN_RATIO_USR_ASSET.name]    = dfData[FeatureName.AMOUNT_MEAN_USR.name] / dfData[FeatureName.AMOUNT_MEAN_ASSET.name]\n",
    "dfData[FeatureName.AMOUNT_STD_RATIO_USR_ASSET.name]    = dfData[FeatureName.AMOUNT_STD_USR.name] / dfData[FeatureName.AMOUNT_STD_ASSET.name]\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_RATIO_USR_ASSET.name] = dfData[FeatureName.TIME_DIFF_MEAN_USR.name] / dfData[FeatureName.TIME_DIFF_MEAN_ASSET.name]\n",
    "dfData[FeatureName.TIME_DIFF_STD_RATIO_USR_ASSET.name] = dfData[FeatureName.TIME_DIFF_STD_USR.name] / dfData[FeatureName.TIME_DIFF_STD_ASSET.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Based Features\n",
    "\n",
    "dfData[FeatureName.TIME_MAX.name] = dfGbs.AggByReceiver(colName = 'Transaction Time', grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "dfData[FeatureName.TIME_MIN.name] = dfGbs.AggByReceiver(colName = 'Transaction Time', grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "\n",
    "dfData[FeatureName.TIME_INTERVL_USR.name] = ((dfData[FeatureName.TIME_MAX.name] - dfData[FeatureName.TIME_MIN.name])).dt.total_seconds()\n",
    "\n",
    "# Frequency of the User Transactions\n",
    "dfData[FeatureName.TSX_FREQ_HZ_USR.name] = dfData[FeatureName.TSX_COUNT_USR.name] / dfData[FeatureName.TIME_INTERVL_USR.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gas ratio features(experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratios between the user to the mean of all users.\n",
    "dfData[FeatureName.GAS_PRICE_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_PRICE_MEAN_ASSET.name]\n",
    "dfData[FeatureName.GAS_LIMIT_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_LIMIT_MEAN_USR.name] / dfData[FeatureName.GAS_LIMIT_MEAN_ASSET.name]\n",
    "dfData[FeatureName.GAS_USED_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_USED_MEAN_USR.name] / dfData[FeatureName.GAS_USED_MEAN_ASSET.name] \n",
    "#Gas Price', 'Gas Limit', 'Gas Used'\n",
    "dfData[FeatureName.GAS_PRICE_LIMIT_RATIO.name] = dfData['Gas Price'] / dfData['Gas Limit']\n",
    "dfData[FeatureName.GAS_PRICE_USED_RATIO.name] = dfData['Gas Price'] / dfData['Gas Used']\n",
    "dfData[FeatureName.GAS_USED_LIMIT_RATIO.name] = dfData['Gas Used'] / dfData['Gas Limit'] \n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_LIMIT_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_LIMIT_MEAN_USR.name]\n",
    "dfData[FeatureName.GAS_PRICE_USED_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_USED_MEAN_USR.name]\n",
    "dfData[FeatureName.GAS_USED_LIMIT_RATIO_MEAN.name] = dfData[FeatureName.GAS_USED_MEAN_USR.name] / dfData[FeatureName.GAS_PRICE_MEAN_USR.name] \n",
    "\n",
    "\n",
    "#Compare it to 75 quantile (TSX Gas Price / Quantile(75) of Gas Price).\n",
    "dfData[FeatureName.GAS_PRICE_QUANTILE_RATIO.name] = dfData['Gas Price'] / dfData[FeatureName.GAS_PRICE_QUANTILE_USR.name]\n",
    "dfData[FeatureName.GAS_LIMIT_QUANTILE_RATIO.name] = dfData['Gas Limit'] / dfData[FeatureName.GAS_LIMIT_QUANTILE_USR.name]\n",
    "dfData[FeatureName.GAS_USED_QUANTILE_RATIO.name] =  dfData['Gas Used'] / dfData[FeatureName.GAS_USED_QUANTILE_USR.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature to indicate first transaction\n",
    "dfData[FeatureName.MIN_INDICATOR.name] = 0 ; dfData.loc[dfData['Transaction Time'] == dfData[FeatureName.TIME_MIN.name], FeatureName.MIN_INDICATOR.name] = 1 \n",
    "### TODO !!! this can be invorrect. it will need a review !!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56\n",
    "#Create features based on the currency of the transactions:\n",
    "# 1. The number of different types of currencies per user. <-- done previously = dfData[FeatureName.COIN_TYPE_COUNT_USR.name]\n",
    "# 2. The average of the number of types of all user for an asset. <-- groupby asset , mean(number of different types of currencies per user)\n",
    "# 3. The ratio between a specific user to the average of the asset. --> 1/2\n",
    "    \n",
    "\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_USR_MEAN_ASSET.name]    = dfGbs.AvgByUserCoinType()\n",
    "dfData[FeatureName.COIN_TYPE_USR_MEAN_ASSET_RATIO.name]  = dfData[FeatureName.COIN_TYPE_COUNT_USR.name] / dfData[FeatureName.COIN_TYPE_COUNT_USR_MEAN_ASSET.name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Pre Processing (For Training Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData_ = dfData.copy(deep=True) ###<<-- I create a copy of data frame for experiment with categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing Data\n",
    "dfData.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "dfData.fillna(0, inplace = True)\n",
    "dfX = dfData[lSlctdFeatures].copy()\n",
    "for catColName in lCatFeatures:\n",
    "    dfX[catColName], _ =  pd.factorize(dfX[catColName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data for Classifier\n",
    "\n",
    "lNumericalFeatures = [featureName for featureName in lSlctdFeatures if featureName not in lCatFeatures]\n",
    "\n",
    "mX = dfX[lNumericalFeatures].to_numpy()\n",
    "mC = dfX[lCatFeatures].to_numpy()\n",
    "vY = dfData['Label'].to_numpy()\n",
    "# Scaling the data\n",
    "hStdScaler = StandardScaler() #<! Don't touch categorial data\n",
    "mX = hStdScaler.fit_transform(mX)\n",
    "mX = np.concatenate((mX, mC), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, test_size = testSetRatio, random_state = randomState, stratify = vY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "selector = SelectKBest(f_classif, k=50).fit(mX, vY)#.fit_transform(X, y)\n",
    "mXTrain_ = selector.transform(mXTrain)\n",
    "mXTest_ = selector.transform(mXTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.get_support()\n",
    "#np.unique(selector.get_support(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "treeModel = tree.DecisionTreeClassifier()\n",
    "treeModel.fit(mXTrain_, vYTrain)\n",
    "vYPred_ = treeModel.predict(mXTest_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayConfusionMatrix(vYTest, vYPred_, lClasses = treeModel.classes_)\n",
    "dsScoreSumm = GenClassifierSummaryResults(vYTest, vYPred_)\n",
    "dfScoreSummary  = pd.DataFrame(dsScoreSumm, columns = ['Score'])\n",
    "dfScoreSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lNumericalFeatures = [featureName for featureName in lSlctdFeatures if featureName not in lCatFeatures]\n",
    "lTotalFeatures = lNumericalFeatures + lCatFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for selector.get_support()\n",
    "lTotalFeatures_ = []\n",
    "for f, b in zip(lTotalFeatures, selector.get_support()):\n",
    "    if b:\n",
    "        lTotalFeatures_.append(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50,50))\n",
    "tree.plot_tree(treeModel,feature_names=lTotalFeatures_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp\n",
    "text_representation = tree.export_text(treeModel)\n",
    "pp(text_representation)#print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(treeModel, out_file=None, \n",
    "                                feature_names=lTotalFeatures_,  \n",
    "                                filled=True)\n",
    "\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "viz = dtreeviz(treeModel, mXTrain_, vYTrain,\n",
    "                #target_name=\"target\",\n",
    "                feature_names=lTotalFeatures_\n",
    "                )\n",
    "\n",
    "viz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####TODO: do feature selection using selectfrommode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "selector = SelectFromModel(estimator=treeModel, max_features= 50).fit(mXTrain, vYTrain)\n",
    "\n",
    "selector.max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.value_counts()\n",
    "#unique, counts = np.unique(selector.get_support(), return_counts=True)\n",
    "np.unique(selector.get_support(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selector.estimator_\n",
    "\n",
    "selector.threshold_\n",
    "\n",
    "#selector.get_support()\n",
    "#selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b091ae1a5f61fa4269f1f2c4a075dfd3ba6d6b741f8802b3932e01e064097caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
