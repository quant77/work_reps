{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CyVers](https://i.imgur.com/yyhmZET.png)](https://www.cyvers.ai/)\n",
    "\n",
    "# SASA and SAMA Data Set - Exploratory Data Analysis (EDA)\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital Royi@cyvers.ai\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | Name            | Content / Changes     |\n",
    "|---------|------------|-----------------|-----------------------|\n",
    "| 1.0.000 | 14/07/2022 | Royi Avital     | First version         |\n",
    "|         |            |                 |                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Miscellaneous\n",
    "import datetime\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# EDA Tools\n",
    "import ppscore as pps #<! See https://github.com/8080labs/ppscore -> pip install git+https://github.com/8080labs/ppscore.git\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, tree\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensemble Engines\n",
    "import lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "from ipywidgets import interact, Dropdown, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# DATA_FOLDER_NAME    = 'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_NAME    = 'DataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet'\n",
    "DATA_FILE_EXT       = 'csv'\n",
    "\n",
    "PROJECT_DIR_NAME = 'CyVers' #<! Royi: Anton, don't change it, it should be a team constant\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after / before `CyVers`\n",
    "\n",
    "# Feature extractors constants\n",
    "\n",
    "# Assets\n",
    "# By amount:\n",
    "SUM_ASSET       = 'SUM (Asset)'\n",
    "MEAN_ASSET      = 'MEAN (Asset)'\n",
    "STD_ASSET       = 'STD (Asset)'\n",
    "VAR_ASSET       = 'VAR (Asset)'\n",
    "MEDIAN_ASSET    = 'MEDIAN (Asset)'\n",
    "COUNT_ASSET     = 'COUNT (Asset)'\n",
    "MIN_ASSET       = 'MIN (Asset)'\n",
    "MAX_ASSET       = 'MAX (Asset)'\n",
    "# By time:\n",
    "TD_MEAN_ASSET   = 'TD_MEAN (Asset)'\n",
    "TD_STD_ASSET    = 'TD_STD (Asset)'\n",
    "TD_MEDIAN_ASSET = 'TD_MEDIAN (Asset)'\n",
    "TD_MIN_ASSET    = 'TD_MIN (Asset)'\n",
    "TD_MAX_ASSET    = 'TD_MAX (Asset)'\n",
    "\n",
    "# User\n",
    "SUM_USR         = 'SUM (User)'\n",
    "MEAN_USR        = 'MEAN (User)'\n",
    "STD_USR         = 'STD (User)'\n",
    "VAR_USR         = 'VAR (User)'\n",
    "MEDIAN_USR      = 'MEDIAN (User)'\n",
    "COUNT_USR       = 'COUNT (User)'\n",
    "MIN_USR         = 'MIN (User)'\n",
    "MAX_USR         = 'MAX (User)'\n",
    "# By time:\n",
    "TD_MEAN_USR     = 'TD_MEAN (User)'\n",
    "TD_STD_USR      = 'TD_STD (User)'\n",
    "TD_MEDIAN_USR   = 'TD_MEDIAN (User)'\n",
    "TD_MIN_USR      = 'TD_MIN (User)'\n",
    "TD_MAX_USR      = 'TD_MAX (User)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CyVers Packages\n",
    "from DataSetsAuxFun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "csvFileName = 'AttacksDataSet_2022_07_13.csv'\n",
    "\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "runTsne = False\n",
    "\n",
    "# Amount USD Outlier threshold\n",
    "amountUsdOutlierThr = 1e9\n",
    "\n",
    "testSetRatio = 1.0 / 3.0\n",
    "randomState = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section adds features and engineers them.  \n",
    "It is assuemd the files havd a single unique `Sender`. Hence all analysis is done on the eceivers.\n",
    "\n",
    "\n",
    "The features are:\n",
    "\n",
    " 1. \n",
    "\n",
    "Remarks:\n",
    "\n",
    " *  Features x-y are time / frequency related.\n",
    " *  Features z-t are trasnaction realted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vFeatures = dfData.columns\n",
    "vFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of the User Transactions\n",
    "dfData['TrnsFrequency [Hz] (User)'] = dfData['COUNT (User)'] / dfData['Time Interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio Between User Std to Asset STD\n",
    "\n",
    "dfData['Amount Ratio']  = dfData['STD (User)'] / dfData['STD (Asset)']\n",
    "dfData['Time Ratio']    = dfData['TD_STD (User)'] / dfData['TD_STD (Asset)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features for analysis\n",
    "lSlctdFeatures  = ['Amount [USD]', 'Receiver Type', 'Label', 'SUM (Asset)', 'MEAN (Asset)',\n",
    "       'STD (Asset)', 'VAR (Asset)', 'MEDIAN (Asset)', 'COUNT (Asset)',\n",
    "       'MIN (Asset)', 'MAX (Asset)', 'TD_MEAN (Asset)', 'TD_STD (Asset)',\n",
    "       'TD_MEDIAN (Asset)', 'TD_MIN (Asset)', 'TD_MAX (Asset)', 'Hour',\n",
    "       'Weekday', 'SUM (User)', 'MEAN (User)', 'STD (User)', 'VAR (User)',\n",
    "       'MEDIAN (User)', 'COUNT (User)', 'MIN (User)', 'MAX (User)',\n",
    "       'TD_MEAN (User)', 'TD_STD (User)', 'TD_MEDIAN (User)', 'TD_MIN (User)',\n",
    "       'TD_MAX (User)', 'Time Interval', 'TrnsFrequency [Hz] (User)', 'Amount Ratio', 'Time Ratio']\n",
    "# lSlctdFeatures  = ['Amount', 'Num Trns User', 'Sum Value User', 'STD Value User', 'Max Value User', 'Min Value User', 'Active Duration User', 'Frequency Trns. / Days', 'STD Time Diff', 'Max Time Diff', 'Min Time Diff']\n",
    "numFeatures     = len(lSlctdFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Scatter of teh Features\n",
    "\n",
    "oDropdwon = Dropdown(\n",
    "    options     = lSlctdFeatures,\n",
    "    value       = 'Amount [USD]',\n",
    "    description = 'Select Feature:',\n",
    "    style       = {'description_width' : 'initial'}\n",
    ")\n",
    "\n",
    "interact(lambda yColName: DisplayScatterFeature(dfData, 'Label', yColName, 'Suspicious'), yColName = oDropdwon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Density of the Features\n",
    "\n",
    "oDropdwon = Dropdown(\n",
    "    options     = lSlctdFeatures,\n",
    "    value       = 'Amount [USD]',\n",
    "    description = 'Select Feature:',\n",
    "    style       = {'description_width' : 'initial'}\n",
    ")\n",
    "\n",
    "interact(lambda yColName: DisplayKdeFeature(dfData, yColName, 'Label', 'Suspicious'), yColName = oDropdwon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing Data\n",
    "dfData.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "dfData.fillna(0, inplace = True)\n",
    "dfX = dfData[dfData.columns[~dfData.columns.isin(['Unnamed: 0', 'Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Amount', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type', 'Label'])]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data for Classifier\n",
    "\n",
    "mX = dfX.to_numpy()\n",
    "vY = dfData['Label'].to_numpy()\n",
    "# Scaling the data\n",
    "hStdScaler = StandardScaler()\n",
    "mX = hStdScaler.fit_transform(mX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTmp = dfData[dfData.columns[~dfData.columns.isin(['Unnamed: 0', 'Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Amount', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type', 'Label'])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lSlctdFeatures = dfTmp.columns.to_list()\n",
    "lSlctdFeatures = dfX.columns.to_list()\n",
    "type(lSlctdFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTmp = dfData[lSlctdFeatures + ['Label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTmp['Label'] = pd.Categorical(dfTmp['Label'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature PPS - Which featuers are important?\n",
    "\n",
    "# Pay attention, cross validation is K-Fold -> Don't over split the data\n",
    "mPPS = pps.matrix(dfTmp, **{'cross_validation': 5, 'random_seed': randomState})[['x', 'y', 'ppscore']].pivot(columns = 'x', index = 'y', values = 'ppscore') #<! We should set `Label` as a categorial variable\n",
    "\n",
    "# Visualization of PPS\n",
    "hF, hA = plt.subplots(figsize = (30, 30))\n",
    "sns.heatmap(mPPS, annot = True, fmt = '.2f', cmap = plt.get_cmap('coolwarm'), cbar = False, vmin = 0, vmax = 1, ax = hA) \n",
    "\n",
    "plt.setp(hA.get_xticklabels(), ha = \"center\", rotation = 45)\n",
    "plt.setp(hA.get_yticklabels(), rotation = 'horizontal')\n",
    "hA.set_title('Predictive Power Score (PPS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation the columns are legit\n",
    "dfX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# TODO: Split by Files\n",
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, test_size = testSetRatio, random_state = randomState, stratify = vY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbModel = XGBClassifier(use_label_encoder = False)\n",
    "xgbModel.fit(mXTrain, vYTrain)\n",
    "vYPred = xgbModel.predict(mXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mConfMat = confusion_matrix(vYTest, vYPred, labels = xgbModel.classes_)\n",
    "cmDisp = ConfusionMatrixDisplay(confusion_matrix = mConfMat, display_labels = xgbModel.classes_)\n",
    "\n",
    "\n",
    "cmPlot = cmDisp.plot()\n",
    "hA = cmPlot.ax_\n",
    "hA.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores Summary \n",
    "\n",
    "dsScoreSumm     = GenClassifierSummaryResults(vYTest, vYPred)\n",
    "dfScoreSummary  = pd.DataFrame(dsScoreSumm, columns = ['Score'])\n",
    "dfScoreSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7eecc89e9756f599c7795c711b2e1de4865f3e2c067be515b73e3b7137ab82cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
