{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CyVers](https://i.imgur.com/yyhmZET.png)](https://www.cyvers.ai/)\n",
    "\n",
    "# BlockChain Attack Data Set - Exploratory Data Analysis (EDA)\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital Royi@cyvers.ai\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | Content / Changes                      |\n",
    "|---------|------------|----------------------------------------|\n",
    "| 0.1.000 | 30/06/2022 | First version                          |\n",
    "|         |            |                                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Misc\n",
    "import datetime\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# EDA Tools\n",
    "import ppscore as pps #<! See https://github.com/8080labs/ppscore -> pip install git+https://github.com/8080labs/ppscore.git\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, tree\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import catboost as cb\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensemble Engines\n",
    "import lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "from ipywidgets import interact, Dropdown, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FOLDER_NAME    = 'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet0'\n",
    "DATA_FILE_EXT       = 'csv'\n",
    "\n",
    "PROJECT_DIR_NAME = 'CyVers' #<! Royi: Anton, don't change it, it should be a team constant\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after / before `CyVers`\n",
    "\n",
    "# Feature extractors constants\n",
    "\n",
    "# Assets\n",
    "# By amount:\n",
    "SUM_ASSET       = 'SUM (Asset)'\n",
    "MEAN_ASSET      = 'MEAN (Asset)'\n",
    "STD_ASSET       = 'STD (Asset)'\n",
    "VAR_ASSET       = 'VAR (Asset)'\n",
    "MEDIAN_ASSET    = 'MEDIAN (Asset)'\n",
    "COUNT_ASSET     = 'COUNT (Asset)'\n",
    "MIN_ASSET       = 'MIN (Asset)'\n",
    "MAX_ASSET       = 'MAX (Asset)'\n",
    "# By time:\n",
    "TD_MEAN_ASSET   = 'TD_MEAN (Asset)'\n",
    "TD_STD_ASSET    = 'TD_STD (Asset)'\n",
    "TD_MEDIAN_ASSET = 'TD_MEDIAN (Asset)'\n",
    "TD_MIN_ASSET    = 'TD_MIN (Asset)'\n",
    "TD_MAX_ASSET    = 'TD_MAX (Asset)'\n",
    "\n",
    "# User\n",
    "SUM_USR         = 'SUM (User)'\n",
    "MEAN_USR        = 'MEAN (User)'\n",
    "STD_USR         = 'STD (User)'\n",
    "VAR_USR         = 'VAR (User)'\n",
    "MEDIAN_USR      = 'MEDIAN (User)'\n",
    "COUNT_USR       = 'COUNT (User)'\n",
    "MIN_USR         = 'MIN (User)'\n",
    "MAX_USR         = 'MAX (User)'\n",
    "# By time:\n",
    "TD_MEAN_USR     = 'TD_MEAN (User)'\n",
    "TD_STD_USR      = 'TD_STD (User)'\n",
    "TD_MEDIAN_USR   = 'TD_MEDIAN (User)'\n",
    "TD_MIN_USR      = 'TD_MIN (User)'\n",
    "TD_MAX_USR      = 'TD_MAX (User)' \n",
    "#######\n",
    "HOUR            = 'Hour'\n",
    "WEEKDAY         = 'Weekday'\n",
    "TIME_INTRVL     = 'Time Interval'\n",
    "\n",
    "test_train_selection_proportion_ = 0.7\n",
    "###list of numeric columns\n",
    "num_cols = ['Amount','Amount [USD]',  SUM_ASSET, MEAN_ASSET, STD_ASSET, VAR_ASSET, MEDIAN_ASSET, COUNT_ASSET, MIN_ASSET, MAX_ASSET, TD_MEAN_ASSET, TD_STD_ASSET, TD_MEDIAN_ASSET , TD_MIN_ASSET, TD_MAX_ASSET, \n",
    "                                      SUM_USR, MEAN_USR, STD_USR, VAR_USR, MEDIAN_USR, COUNT_USR, MIN_USR, MAX_USR, TD_MEAN_USR, TD_STD_USR, TD_MEDIAN_USR, TD_MIN_USR, TD_MAX_USR, HOUR, WEEKDAY, TIME_INTRVL]\n",
    "categor_cols = ['Currency', 'Currency Type' , 'Receiver Type']\n",
    "\n",
    "numAttacksColName = 'Number of Attacks'\n",
    "attackTypeColName = 'Attack Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CyVers Packages\n",
    "from DataSetsAuxFun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "runTsne = False\n",
    "\n",
    "# Amount USD Outlier threshold\n",
    "amountUsdOutlierThr = 1e9\n",
    "\n",
    "testSetRatio = 1.0 / 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def print_scores(preds, y_test):\n",
    "    print('recall : ' , recall_score(y_test,preds))#(preds, y_test))\n",
    "    print('Test Precision Score: ' , precision_score(y_test, preds))#(preds, y_test))\n",
    "    print('Test F1 Score: ' , fbeta_score(y_test,preds, beta=1))\n",
    "    print('Confusion Matrix: \\n' , confusion_matrix(y_test,preds))\n",
    "\n",
    "def model_scores(preds, y_test):\n",
    "    return recall_score(y_test,preds) , precision_score(y_test,preds) , fbeta_score(y_test,preds, beta=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "lCsvFile = ExtractCsvFiles(dataSetRotoDir, folderNamePattern = DATA_FOLDER_PATTERN)\n",
    "print(f'The number of file found: {len(lCsvFile)}')\n",
    "\n",
    "# dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "dfData, dAssetFile = LoadCsvFilesDf(lCsvFile, baseFoldePath = '')\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f\"The number of rows (Samples): {numRows}, The number of columns: {numCols}, number of unique sender id's: {dfData['Sender ID'].unique().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time data into Pandas format\n",
    "dfData['Transaction Time'] = pd.to_datetime(dfData['Transaction Time'], infer_datetime_format = 'True') #<! Stable time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by transaction date\n",
    "dfData.sort_values('Transaction Time', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about the Data Before Pre Processing\n",
    "\n",
    "1. See the labeled cases.\n",
    "2. Count the Labels data.\n",
    "3. Number of unique assets.\n",
    "4. Pandas' `info()` and `describe()`.\n",
    "\n",
    "After this phase, the data is _read only_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at attack cases\n",
    "dfData.loc[dfData['Label'] == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfData['Sender ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing\n",
    "\n",
    "1. Remove invalid data.\n",
    "2. Remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting invalid `Amount USD`\n",
    "\n",
    "dsInValidTrnsUsd = ((dfData['Amount [USD]'] == 0) | (dfData['Amount [USD]'].isna()) | (dfData['Amount [USD]'] == ''))\n",
    "\n",
    "print(f'Number of invalid `Amount [USD]`: {dsInValidTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid data\n",
    "dfData.drop(dfData.index[dsInValidTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Outliers in the `Amount [USD]`\n",
    "\n",
    "dsOutlierTrnsUsd = ((dfData['Amount [USD]'] >= amountUsdOutlierThr) | (dfData['Amount [USD]'] <= 0))\n",
    "\n",
    "print(f'Number of outliers `Amount [USD]`: {dsOutlierTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "dfData.drop(dfData.index[dsOutlierTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on this is the data to work with\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the Data\n",
    "\n",
    "Basic infomration about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section adds features and engineers them.  \n",
    "Most features work on the `Sender ID` group.\n",
    "\n",
    "#### Amount Based Features:\n",
    "\n",
    "1. The STD of the user vs the average STD of all other users of the asset.\n",
    "2. The Median of the user vs the average STD of all other users of the asset.\n",
    "3. \n",
    "\n",
    "#### Date Based Features\n",
    "\n",
    "1. The day of the week.\n",
    "2. Weekend.\n",
    "3. Hour of the day.\n",
    "4. STD fo the time difference of the user vs. the avergae of all other users.\n",
    "5. Median fo the time difference of the user vs. the avergae of all other users.\n",
    "\n",
    "**Remark**: For wallets with a lot of activity we need to analyze the \"activity hours\" and profile it.\n",
    "\n",
    "\n",
    "The features are:\n",
    "\n",
    " 1. Day of the Week.\n",
    "\n",
    "Remarks:\n",
    "\n",
    " *  Features x-y are time / frequency related.\n",
    " *  Features z-t are trasnaction realted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process\n",
    "\n",
    "dfGbs = GrpBySender(dfData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based\n",
    "'''    TYPE_SUM     TYPE_MEAN            TYPE_STD              TYPE_VAR                    TYPE_MEDIAN           TYPE_COUNT                  TYPE_MIN              TYPE_MAX                    '''\n",
    "#sum_s       = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "#mean_s      = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "#std_s       = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "#var_s       = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "#median_s    = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "#count_s     = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "#min_s       = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "#max_s       = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "\n",
    "#dfData[SUM_ASSET]     = sum_s\n",
    "#dfData[MEAN_ASSET]    = mean_s\n",
    "#dfData[STD_ASSET]     = std_s\n",
    "#dfData[VAR_ASSET]     = var_s\n",
    "#dfData[MEDIAN_ASSET]  = median_s\n",
    "#dfData[COUNT_ASSET]   = count_s\n",
    "#dfData[MIN_ASSET]     = min_s\n",
    "#dfData[MAX_ASSET]     = max_s\n",
    "\n",
    "sum_s       = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_SUM)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s      = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s       = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s       = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_VAR)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s    = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s     = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s       = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MIN)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s       = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MAX)#dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "\n",
    "dfData[SUM_ASSET]     = sum_s\n",
    "dfData[MEAN_ASSET]    = mean_s\n",
    "dfData[STD_ASSET]     = std_s\n",
    "dfData[VAR_ASSET]     = var_s\n",
    "dfData[MEDIAN_ASSET]  = median_s\n",
    "dfData[COUNT_ASSET]   = count_s\n",
    "dfData[MIN_ASSET]     = min_s\n",
    "dfData[MAX_ASSET]     = max_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "'TYPE_TIME_DIFF_MEAN      TYPE_TIME_DIFF_STD TYPE_TIME_DIFF_MEDIAN  TYPE_TIME_DIFF_MIN      TYPE_TIME_DIFF_MAX'      \n",
    "#td_mean_s   = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "#td_std_s    = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "#td_median_s = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "#td_min_s    = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "#td_max_s    = dfGbs._SentValue(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "#dfData[TD_MEAN_ASSET]   = td_mean_s\n",
    "#dfData[TD_STD_ASSET]    = td_std_s\n",
    "#dfData[TD_MEDIAN_ASSET] = td_median_s\n",
    "#dfData[TD_MIN_ASSET]    = td_min_s\n",
    "#dfData[TD_MAX_ASSET]    = td_max_s\n",
    "\n",
    "td_mean_s   = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "\n",
    "\n",
    "dfData[TD_MEAN_ASSET]   = td_mean_s\n",
    "dfData[TD_STD_ASSET]    = td_std_s\n",
    "dfData[TD_MEDIAN_ASSET] = td_median_s\n",
    "dfData[TD_MIN_ASSET]    = td_min_s\n",
    "dfData[TD_MAX_ASSET]    = td_max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "dfData['Hour']      = dfData['Transaction Time'].dt.hour\n",
    "dfData['Weekday']   = dfData['Transaction Time'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based (User)\n",
    "'''    TYPE_SUM     TYPE_MEAN            TYPE_STD              TYPE_VAR                    TYPE_MEDIAN           TYPE_COUNT                  TYPE_MIN              TYPE_MAX                    '''\n",
    "#sum_s       = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "#mean_s      = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "#std_s       = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "#var_s       = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "#median_s    = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "#count_s     = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "#min_s       = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "#max_s       = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "\n",
    "#dfData[SUM_USR]     = sum_s\n",
    "#dfData[MEAN_USR]    = mean_s\n",
    "#dfData[STD_USR]     = std_s\n",
    "#dfData[VAR_USR]     = var_s\n",
    "#dfData[MEDIAN_USR]  = median_s\n",
    "#dfData[COUNT_USR]   = count_s\n",
    "#dfData[MIN_USR]     = min_s\n",
    "#dfData[MAX_USR]     = max_s\n",
    "\n",
    "sum_s       = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_SUM)#_AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s      = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEAN)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s       = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_STD)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s       = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_VAR)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s    = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEDIAN)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s     = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_COUNT)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s       = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s       = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)#dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "\n",
    "dfData[SUM_USR]     = sum_s\n",
    "dfData[MEAN_USR]    = mean_s\n",
    "dfData[STD_USR]     = std_s\n",
    "dfData[VAR_USR]     = var_s\n",
    "dfData[MEDIAN_USR]  = median_s\n",
    "dfData[COUNT_USR]   = count_s\n",
    "dfData[MIN_USR]     = min_s\n",
    "dfData[MAX_USR]     = max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based (User)\n",
    "'TYPE_TIME_DIFF_MEAN      TYPE_TIME_DIFF_STD TYPE_TIME_DIFF_MEDIAN  TYPE_TIME_DIFF_MIN      TYPE_TIME_DIFF_MAX'      \n",
    "#td_mean_s   = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "#td_std_s    = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "#td_median_s = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "#td_min_s    = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "#td_max_s    = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "#dfData[TD_MEAN_USR]   = td_mean_s\n",
    "#dfData[TD_STD_USR]    = td_std_s\n",
    "#dfData[TD_MEDIAN_USR] = td_median_s\n",
    "#dfData[TD_MIN_USR]    = td_min_s\n",
    "#dfData[TD_MAX_USR]    = td_max_s\n",
    "\n",
    "td_mean_s   = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[TD_MEAN_USR]   = td_mean_s\n",
    "dfData[TD_STD_USR]    = td_std_s\n",
    "dfData[TD_MEDIAN_USR] = td_median_s\n",
    "dfData[TD_MIN_USR]    = td_min_s\n",
    "dfData[TD_MAX_USR]    = td_max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Time interval calculations for groups-subgroups\n",
    "# need to do approximately this:\n",
    "## dfData.groupby(['Sender ID','Receiver ID'])['Transaction Time'].apply(lambda x: (x.max() - x.min())/ np.timedelta64(1, 's')).shape\n",
    "\n",
    "ds_SentValue = pd.Series(index = dfGbs.dfData.index)\n",
    "for ii in range(len(dfGbs.lSubGrpUsrLabelIdx)):\n",
    "    for i in range(len(dfGbs.lSubGrpUsrLabelIdx[ii])):\n",
    "        ival = dfGbs.dfData['Transaction Time'][dfGbs.lSubGrpUsrLabelIdx[ii][i]]\n",
    "        dd = (ival.max() - ival.min()) / np.timedelta64(1, 's')\n",
    "        ds_SentValue[dfGbs.lSubGrpUsrLabelIdx[ii][i]] =  dd\n",
    "dfData['Time Interval'] = ds_SentValue\n",
    "#### probably should be added to methods file\n",
    "\n",
    "# dfData['Max Time (User)'] = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "# dfData['Min Time (User)'] = dfGbs._AnalyseRecieverId(amountCol = AmountType.AMOUNT_USD, tokenId = None, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "# dfData['Time Interval'] = (dfData['Max Time (User)'] - dfData['Min Time (User)']).dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData_ = dfData.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_input_create(dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ , selection_option = 'file_selection', use_categorical = True):\n",
    "    \n",
    "    dfData[dfData.columns[~dfData.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID',  'Currency Hash','tx_hash', 'Currency',  'Currency Type', 'Receiver Type','Label'])]].fillna(0, inplace=True) \n",
    "    #dfData.fillna(0, inplace=True)\n",
    "    ####################### create inputs for ML algos:\n",
    "    #### get ids of cases attributed to files, then randomly select ids for train and test subsets\n",
    "\n",
    "    if selection_option == 'file_selection':\n",
    "        all_ids = list(dAssetFile.keys()) \n",
    "        rnd_choices_train = random.choices(all_ids, k = int(test_train_selection_proportion_*len(all_ids)))\n",
    "        \n",
    "        rnd_choices_test = list(set(all_ids) - set(rnd_choices_train)) + list(set(rnd_choices_train) - set(all_ids))\n",
    "\n",
    "        for cat_col in categor_cols:\n",
    "            dfData[cat_col] = dfData[cat_col].astype(\"category\", copy = False)\n",
    "            \n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        dfData[num_cols] = scaler.fit_transform(dfData[num_cols])\n",
    "\n",
    "        \n",
    "                \n",
    "        dfData_train = dfData[dfData['Sender ID'].isin(rnd_choices_train)]\n",
    "        dfData_test = dfData[dfData['Sender ID'].isin(rnd_choices_test)]\n",
    "        \n",
    "        \n",
    "        if use_categorical:\n",
    "            X_train = dfData_train[dfData_train.columns[~dfData_train.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID',  'Currency Hash','tx_hash','Label'])]]\n",
    "            X_train.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "            Y_train = dfData_train['Label']\n",
    "        \n",
    "            X_test = dfData_test[dfData_train.columns[~dfData_test.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID',  'Currency Hash','tx_hash','Label'])]]\n",
    "            X_test.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "            Y_test = dfData_test['Label']\n",
    "            \n",
    "\n",
    "        else:\n",
    "            X_train = dfData_train[dfData_train.columns[~dfData_train.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type','tx_hash','Label'])]]\n",
    "            X_train.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "            Y_train = dfData_train['Label']\n",
    "        \n",
    "            X_test = dfData_test[dfData_train.columns[~dfData_test.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type','tx_hash','Label'])]]\n",
    "            X_test.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "            Y_test = dfData_test['Label']\n",
    "                \n",
    "\n",
    "   \n",
    "    if selection_option == 'simple_selection':\n",
    "               \n",
    "        dfData_train, dfData_test = train_test_split(dfData, test_size=(1 - test_train_selection_proportion_), random_state=seedNum, stratify=dfData[['Label']])\n",
    "\n",
    "        #X_train = dfData[dfData.columns[~dfData.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type','tx_hash','Label'])]].to_numpy()\n",
    "        X_train = dfData_train[dfData_train.columns[~dfData_train.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type','tx_hash','Label'])]]\n",
    "        X_train.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "        Y_train = dfData_train['Label']\n",
    "    \n",
    "        X_test = dfData_test[dfData_train.columns[~dfData.columns.isin(['Transaction ID', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Currency', 'Currency Hash', 'Currency Type', 'Receiver Type','tx_hash','Label'])]]\n",
    "        X_test.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "        Y_test = dfData_test['Label']\n",
    "        \n",
    "        \n",
    "    \n",
    "        #sc = StandardScaler()\n",
    "        #X_scaled = sc.fit_transform(X)\n",
    "        #X_train, X_test, Y_train, Y_test = train_test_split( X_scaled, Y, test_size=test_train_selection_proportion_, random_state=42) #<! Royi: You should use startified split as the data is imbalanced\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def model_train(x,y,eval = None, model_ = 'xgboost'):\n",
    "    if model_ == 'xgboost':\n",
    "        model = XGBClassifier(tree_method=\"gpu_hist\", random_state=seedNum, enable_categorical=True)#use_label_encoder=False,#model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "        model.fit(x, y)\n",
    "    if model_ == 'svm':\n",
    "        model = SVC(kernel='linear')\n",
    "        model.fit(x, y)\n",
    "\n",
    "    if model_ == 'nn':\n",
    "        n_vars = x.shape[1]\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=1e-5,  hidden_layer_sizes=(n_vars, 2*n_vars), random_state=1)\n",
    "        model.fit(x, y)\n",
    "    \n",
    "    if model_ == 'catboost':\n",
    "        train_data = cb.Pool(x, y, cat_features=['Currency', 'Currency Type', 'Receiver Type']) \n",
    "        eval_data = eval\n",
    "        model = CatBoostClassifier(iterations=10)\n",
    "        model.fit(train_data, eval_set=eval_data)\n",
    "            \n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "@timer\n",
    "def model_inference(x, model):#, model_ = 'xgboost'):\n",
    "    return model.predict(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_training(k_fold, dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,selection_option = 'file_selection', model_ = 'xgboost'):\n",
    "\n",
    "    max = 0 ; r = []\n",
    "    for i in range(k_fold):\n",
    "        \n",
    "        if model_ == 'xgboost':\n",
    "            X_train, Y_train, X_test, Y_test ,  = ml_input_create(dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,selection_option = selection_option, use_categorical = True)\n",
    "            model = model_train(X_test, Y_test,eval = None, model_ = 'xgboost')\n",
    "            y_pred_xgboost = model_inference(X_test, model)#y_pred_xgboost = model.predict(X_test)\n",
    "            \n",
    "            _, _, f1_score = model_scores(y_pred_xgboost, Y_test)\n",
    "            if f1_score > max : \n",
    "                max = f1_score\n",
    "                r = [max, model, X_train, Y_train, X_test, Y_test]\n",
    "            \n",
    "        \n",
    "        if model_ == 'svm':\n",
    "            \n",
    "            X_train, Y_train, X_test, Y_test = ml_input_create(dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,selection_option = selection_option, use_categorical = False)\n",
    "            model = model_train(X_test, Y_test,eval = None, model_ = 'svm')\n",
    "            y_pred = model_inference(X_test, model) #y_pred = model.predict(X_test)\n",
    "\n",
    "            \n",
    "            _, _, f1_score = model_scores(y_pred, Y_test)\n",
    "            if f1_score > max : \n",
    "                max = f1_score\n",
    "                r = [max, model]\n",
    "            \n",
    "        if model_ == 'catboost':\n",
    "            X_train, Y_train, X_test, Y_test  = ml_input_create(dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_  ,selection_option = selection_option, use_categorical = True)\n",
    "            #train_data = cb.Pool(X_train, Y_train, cat_features=['Currency', 'Currency Type', 'Receiver Type']) \n",
    "            eval_data = cb.Pool(X_test, Y_test, cat_features=['Currency', 'Currency Type', 'Receiver Type'])\n",
    "            #model = CatBoostClassifier(iterations=10) ;    #model.fit(train_data, eval_set=eval_data)\n",
    "            model = model_train(X_train,Y_train,eval = eval_data, model_ = 'catboost')\n",
    "            preds_catboost_y = model_inference(eval_data, model)#preds_catboost_y = model.predict(eval_data)\n",
    "            #preds_catboost_y = model.predict(X_test)\n",
    "            \n",
    "            \n",
    "            _, _, f1_score = model_scores(preds_catboost_y, Y_test)\n",
    "            if f1_score > max : \n",
    "                max = f1_score\n",
    "                r = [max, model]\n",
    "\n",
    "        if model_ == 'nn':\n",
    "            X_train, Y_train, X_test, Y_test  = ml_input_create(dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,selection_option = selection_option, use_categorical = False)\n",
    "            model = model_train(X_test, Y_test,eval = None, model_ = 'nn')\n",
    "            \n",
    "            y_nn_pred = model.predict(X_test)    \n",
    "            _, _, f1_score = model_scores(y_nn_pred, Y_test)\n",
    "            if f1_score > max : \n",
    "                max = f1_score\n",
    "                r = [max, model]\n",
    "                    \n",
    "            \n",
    "    return r     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r, X_test_sasa, Y_test_sasa, X_test_sama, Y_test_sama = k_fold_training(20, dfData_, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,dfSasaSama ,selection_option = 'file_selection', model_ = 'xgboost')\n",
    "#r, X_test_sasa, Y_test_sasa, X_test_sama, Y_test_sama = k_fold_training(10, dfData, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,dfSasaSama ,selection_option = 'file_selection', model_ = 'svm') ### <<-- forever\n",
    "r  = k_fold_training(10, dfData_, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,dfSasaSama ,selection_option = 'file_selection', model_ = 'catboost')\n",
    "print(r)\n",
    "best_model_ = r[1]\n",
    "y_pred_sasa = model_inference(X_test_sasa, best_model_)#best_model_.predict(X_test_sasa)\n",
    "y_pred_sama = model_inference(X_test_sama, best_model_)#best_model_.predict(X_test_sama)\n",
    "\n",
    "#print_scores(y_pred_xgboost, Y_test)\n",
    "print('sasa scores : ')\n",
    "print_scores(y_pred_sasa, Y_test_sasa)\n",
    "print('sama scores : ')\n",
    "print_scores(y_pred_sama, Y_test_sama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSetsAuxFun_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = model_inference(X_test, best_model_)\n",
    "print_scores(y_, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenClassifierSummaryResults(Y_test, y_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = k_fold_training(10, dfData_, dAssetFile, categor_cols, num_cols , test_train_selection_proportion_ ,selection_option = 'file_selection', model_ = 'xgboost')\n",
    "print(r[0:2])\n",
    "best_model_ = r[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_model_, 'model_old_878.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = load('model_old.joblib') \n",
    "\n",
    "y_pred = model_inference(r[-2], loaded)#best_model_.predict(X_test_sasa)\n",
    "\n",
    "print('scores : ')\n",
    "print_scores(y_pred, r[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4dd14267cae23840dea038347bc16e5034e9d5e8854ee2a5f16737016150660"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
