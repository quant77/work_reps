{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CyVers](https://i.imgur.com/yyhmZET.png)](https://www.cyvers.ai/)\n",
    "\n",
    "# Solidus Blind Test - Exploratory Data Analysis (EDA)\n",
    "\n",
    "> Notebook by:\n",
    "> - Hakan UNAL Hakan@cyvers.ai\n",
    "> - Royi Avital Royi@cyvers.ai\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | Content / Changes                      |\n",
    "|---------|------------|----------------------------------------|\n",
    "| 1.0.000 | 03/06/2022 | First version                          |\n",
    "|         |            |                                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Misc\n",
    "import random\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from platform import python_version\n",
    "\n",
    "# EDA Tools\n",
    "import ppscore as pps #<! See https://github.com/8080labs/ppscore -> pip install git+https://github.com/8080labs/ppscore.git\n",
    "\n",
    "# Ensemble Engines\n",
    "import lightgbm\n",
    "import xgboost\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "from ipywidgets import interact, Dropdown, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FOLDER_NAME    = 'DataSet'\n",
    "DATA_FOLDER_NAME    = 'DataSet/Test'\n",
    "DATA_FILE_EXT       = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "csvFileName = 'Dataset Bitmart.csv'\n",
    "csvFileName = 'All.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time data into Pandas format\n",
    "dfData['Transaction Time'] = pd.to_datetime(dfData['Transaction Time'], infer_datetime_format = 'True') #<! Stable time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section adds features and engineers them.  \n",
    "It is assuemd the files havd a single unique `Sender`. Hence all analysis is done on the eceivers.\n",
    "\n",
    "\n",
    "The features are:\n",
    "\n",
    " 1. \n",
    "\n",
    "Remarks:\n",
    "\n",
    " *  Features x-y are time / frequency related.\n",
    " *  Features z-t are trasnaction realted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data grouped by user as most operations work on users\n",
    "dfGrpUser = dfData.sort_values('Transaction Time').groupby('Receiver ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Features (Transactions)\n",
    "dfData['Num Trns User'] = dfGrpUser['Receiver ID'].transform('size') #<! We sould use `count` instead of `size` to remove NaN\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount Related Features\n",
    "\n",
    "# dfData['Sum Value User'] = dfGrpUser['Amount [USD]'].transform(lambda x: x.sum()) #<! We sould use `count` instead of `size` to remove NaN, Using lambda function is much slower\n",
    "dfData['Sum Value User'] = dfGrpUser['Amount [USD]'].transform('sum') #<! We sould use `count` instead of `size` to remove NaN\n",
    "dfData['Mean Value User'] = dfGrpUser['Amount [USD]'].transform('mean') \n",
    "dfData['STD Value User'] = dfGrpUser['Amount [USD]'].transform('std') \n",
    "dfData['Max Value User'] = dfGrpUser['Amount [USD]'].transform('max') \n",
    "dfData['Min Value User'] = dfGrpUser['Amount [USD]'].transform('min')\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Related Features\n",
    "\n",
    "dfData['First Action User'] = dfGrpUser['Transaction Time'].transform('min')\n",
    "dfData['Last Action User'] = dfGrpUser['Transaction Time'].transform('max')\n",
    "dfData['Active Duration User'] = np.maximum((dfData['Last Action User'] - dfData['First Action User']).dt.total_seconds(), 1) #<! Limiting the minimal period to 1 [Sec] (Will be used for divison)\n",
    "dfData['Frequency Trns. / Days'] = dfData['Num Trns User'] / (dfData['Active Duration User'] / (24 * 3600))\n",
    "\n",
    "# dfData['Diff Trns Time'] = dfGrpUser['Transaction Time'].rolling(2).apply(lambda x: x[1] - x[0], raw = True)\n",
    "# dfData['Diff Trns Time'] = np.NaN\n",
    "# for grpName, dfGroup in dfGrpUser:\n",
    "\n",
    "#     vIndx = dfGroup.index\n",
    "\n",
    "#     for ii, idxVal in enumerate(vIndx):\n",
    "#         if ii == 0:\n",
    "#             continue\n",
    "\n",
    "#         dfData.loc[idxVal, 'Diff Trns Time'] = (dfData.loc[idxVal, 'Transaction Time'] - dfData.loc[vIndx[ii - 1], 'Transaction Time']).total_seconds()\n",
    "\n",
    "dfData['Diff Trns Time'] = dfGrpUser['Transaction Time'].diff().dt.total_seconds()\n",
    "\n",
    "#<! Since we use newly created column we can't use the groups and apply\n",
    "for grpName, dfGroup in dfGrpUser:\n",
    "\n",
    "    vIndx = dfGroup.index\n",
    "\n",
    "    dfData.loc[vIndx, 'Mean Time Diff'] = dfData.loc[vIndx, 'Diff Trns Time'].mean()\n",
    "    dfData.loc[vIndx, 'STD Time Diff']  = dfData.loc[vIndx, 'Diff Trns Time'].std()\n",
    "    dfData.loc[vIndx, 'Max Time Diff']  = dfData.loc[vIndx, 'Diff Trns Time'].max()\n",
    "    dfData.loc[vIndx, 'Min Time Diff']  = dfData.loc[vIndx, 'Diff Trns Time'].min()\n",
    "\n",
    "dfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis & Visualization\n",
    "\n",
    "Thsi section visuazlie the data and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features for analysis\n",
    "lSlctdFeatures  = ['Amount [USD]', 'Num Trns User', 'Sum Value User', 'Mean Value User', 'STD Value User', 'Max Value User', 'Min Value User', 'Active Duration User', 'Frequency Trns. / Days', 'Mean Time Diff', 'STD Time Diff', 'Max Time Diff', 'Min Time Diff']\n",
    "# lSlctdFeatures  = ['Amount [USD]', 'Num Trns User', 'Sum Value User', 'STD Value User', 'Max Value User', 'Min Value User', 'Active Duration User', 'Frequency Trns. / Days', 'STD Time Diff', 'Max Time Diff', 'Min Time Diff']\n",
    "numFeatures     = len(lSlctdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Power Score (PPS)\n",
    "\n",
    "This analysis shows the relation between the different features.  \n",
    "The idea is to try estimate a feature by a different feature as a better way to see the link (Compared to correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive Power Score (PPS)\n",
    "\n",
    "mPPS = pps.matrix(dfData[lSlctdFeatures + ['Label']], **{'cross_validation': 20, 'random_seed': 1234})[['x', 'y', 'ppscore']].pivot(columns = 'x', index = 'y', values = 'ppscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of PPS\n",
    "hF, hA = plt.subplots(figsize = (30, 30))\n",
    "sns.heatmap(mPPS, annot = True, fmt = '.2f', cmap = plt.get_cmap('coolwarm'), cbar = False, vmin = 0, vmax = 1, ax = hA) #<! Below the Diagonal Horizontal predict Vertical (x -> y), Above diagonal Vertical predict Horizontal (y -> x)\n",
    "\n",
    "plt.setp(hA.get_xticklabels(), ha = \"center\", rotation = 45)\n",
    "plt.setp(hA.get_yticklabels(), rotation = 'horizontal')\n",
    "hA.set_title('Predictive Power Score (PPS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valA = pps.score(dfData, 'Num Trns User', 'Label') #<! Predict y by x (pps.score(dfData, 'x', 'y'))\n",
    "valA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valA = pps.score(dfData, 'Label', 'Num Trns User') #<! Predict y by x (pps.score(dfData, 'x', 'y'))\n",
    "valA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGrpLabel = dfData.groupby('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot per Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on a DataFrameGroupBy\n",
    "# Below is Royi's approach, another approach: https://stackoverflow.com/questions/25279810\n",
    "numColsFig = 5\n",
    "numRowsFig = np.ceil(numFeatures / numColsFig).astype('int')\n",
    "\n",
    "hF, mHA = plt.subplots(nrows = numRowsFig, ncols = numColsFig, figsize = (7 * numColsFig, 5 * numRowsFig))\n",
    "\n",
    "def JitterXData( xVal, numSamples, jitterLvl = 0.01 ):\n",
    "    return xVal + jitterLvl * np.random.randn(numSamples)\n",
    "\n",
    "kk = 0\n",
    "vShift = [-0.3, 0.3]\n",
    "vC = [{'c': 'b'}, {'c': 'r'}]\n",
    "vC = [{'c': ['b'], 'label': '0'}, {'c': ['r'], 'label': '1'}]\n",
    "for ii, colName in enumerate(lSlctdFeatures):\n",
    "    for jj, (grpName, dfGroup) in enumerate(dfGrpLabel):\n",
    "        # sns.scatterplot(data = dfGroup, x = ii + vShift[jj], y = colName, ax = mHA.flat[kk], **vC[jj]) #<! mA.flat[kk] Allows linear indexing for non 1D arrays\n",
    "        sns.scatterplot(data = dfGroup, x = JitterXData(ii + vShift[jj], dfGroup.shape[0]), y = colName, ax = mHA.flat[kk], **vC[jj]) #<! Added manual jitter\n",
    "        mHA.flat[kk].tick_params(top = False, bottom = False, labelbottom = False)\n",
    "        mHA.flat[kk].legend(title = 'Suspicious')\n",
    "    kk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hF, hA = plt.subplots(figsize = (20, 10))\n",
    "\n",
    "def DisplayFeature( dfData, xColName, yColName, hA ):\n",
    "    hF, hA = plt.subplots(figsize = (20, 10))\n",
    "    \n",
    "    sns.scatterplot(data = dfData, x = xColName, y = yColName, hue = xColName, ax = hA)\n",
    "    hA.tick_params(top = False, bottom = False, labelbottom = False)\n",
    "    hA.legend(title = 'Suspicious')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "oDropdwon = Dropdown(\n",
    "    options     = lSlctdFeatures,\n",
    "    value       = 'Amount [USD]',\n",
    "    description = 'Select Feature:',\n",
    "    style       = {'description_width' : 'initial'}\n",
    ")\n",
    "\n",
    "interact(lambda yColName: DisplayFeature(dfData, 'Label', yColName, hA), yColName = oDropdwon)\n",
    "\n",
    "# DisplayFeature(dfData, 'Label', 'Amount [USD]', hA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "hF, hA = plt.subplots(figsize = (32, 12))\n",
    "\n",
    "for ii, colName in enumerate(lSlctdFeatures):\n",
    "    sns.scatterplot(data = dfData, x = JitterXData(ii, dfData.shape[0]), y = colName, hue = 'Label', ax = hA) #<! Too crowded\n",
    "    \n",
    "hLegHandles, hLegLabels = hA.get_legend_handles_labels()\n",
    "hA.legend(hLegHandles[:2], hLegLabels[:2], title = 'Suspicious')\n",
    "\n",
    "hA.set_xticks(range(numFeatures), lSlctdFeatures)\n",
    "plt.setp(hA.get_xticklabels(), ha = \"right\", rotation = 45)\n",
    "\n",
    "hA.set_xlabel('Variable')\n",
    "hA.set_ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "hF, hA = plt.subplots(figsize = (32, 12))\n",
    "\n",
    "sns.scatterplot(data = dfData, x = 'Amount [USD]', y = 'Frequency Trns. / Days', hue = 'Label', ax = hA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plot per Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process data:\n",
    "# 1. Flatten all Var columns into a single long columns.\n",
    "# 2. Per element set its Var (in vB) and Cancer (vC)\n",
    "vA = dfData.loc[:, lSlctdFeatures].to_numpy().flatten(order = 'F')\n",
    "vB = np.tile(np.reshape(lSlctdFeatures, (numFeatures, 1)), (1, numRows))\n",
    "vB = vB.flatten(order = 'C')\n",
    "vC = np.tile(dfData.loc[:, 'Label'], (numFeatures,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "hF, hA = plt.subplots(figsize = (32, 12))\n",
    "\n",
    "# for ii, colName in enumerate(dfData.columns[featuresFirstIdx:]):\n",
    "#     sns.scatterplot(data = dfData, x = ii, y = colName, hue = dfData.columns[2], ax = hA) #<! Too crowded\n",
    "    # sns.violinplot(data = dfData, y = colName, x = ii * np.ones(dfData.shape[0]), hue = 'Cancer', split = True, ax = hA) #<! Doesn't work\n",
    "    # sns.swarmplot(data = dfData, x = ii * np.ones(dfData.shape[0]), y = colName, hue = 'Cancer', ax = hA) #<! Doesn't work\n",
    "    # sns.stripplot(data = dfData, x = ii * np.ones(dfData.shape[0]), y = colName, hue = 'Cancer', ax = hA) #<! Doesn't work\n",
    "    \n",
    "\n",
    "\n",
    "# hLegHandles, hLegLabels = hA.get_legend_handles_labels()\n",
    "# hA.legend(hLegHandles[:2], hLegLabels[:2], title = 'Cancer')\n",
    "\n",
    "# hA.set_xlabel('Variable')\n",
    "# hA.set_ylabel('Value')\n",
    "\n",
    "# Usign the Pre Process data works!\n",
    "sns.violinplot(x = vB, y = vA, hue = vC, inner = None, split = True, ax = hA)\n",
    "hA.legend(title = 'Suspicious')\n",
    "plt.setp(hA.get_xticklabels(), ha = \"right\", rotation = 45)\n",
    "hA.set_ylabel('Value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The long tails in the negative direction in some of the features above (For example, feature `Var025`) are due to the `log10()` transform. In order to prevent `-Inf` values a value of `1e-6` was added to all values.\n",
    "\n",
    "Most of the features have large overlap and there is no feature which can, on its own, predict the objective very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution per Variable\n",
    "\n",
    "In this section we'll review the distribution of the classes (Healthy / Sick) per feature.  \n",
    "Good features are the ones which the overlap between the distributions is small (Being more accurate, the mass under the overlapped curves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently not working!\n",
    "\n",
    "# numColsFig = 5\n",
    "# numRowsFig = np.ceil(numFeatures / numColsFig).astype('int')\n",
    "\n",
    "# hF, mHA = plt.subplots(nrows = numRowsFig, ncols = numColsFig, figsize = (5 * numColsFig, 5 * numRowsFig))\n",
    "# # hF.suptitle('Distribution of Features by Classes', fontsize = 16)\n",
    "# # hF.supylabel('Density')\n",
    "\n",
    "# kk = 0\n",
    "# for ii in range(numFeatures):\n",
    "#     sns.kdeplot(data = dfData, x = lSlctdFeatures[ii], hue = 'Label', ax = mHA.flat[kk]) #<! mA.flat[kk] Allows linear indexing for non 1D arrays\n",
    "#     kk += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Age\n",
    "\n",
    "One of the most interesting question is how does the feature (Protein) profile changes with age.  \n",
    "The idea is to understand whether a feature is a good predictor of the cancer or the age (Which is a predictor of the cancer in the general population).\n",
    "\n",
    "Some remarks:\n",
    "\n",
    "1. The _positive_ and _negative_ groups have different age profile. For instance, there is no _positive_ case with age below 36.  \n",
    "2. Most of the features show little / no correlation with age. Which means they have a potential to predict a phenomenon regardless of the age.\n",
    "\n",
    "\n",
    "> It is advised to keep the meta data fragmentation low while keeping the positive / negative ratio equal at each fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Plot: Age vs. Feature\n",
    "\n",
    "numColsFig = 6\n",
    "numRowsFig = np.ceil(numFeatures / numColsFig).astype('int')\n",
    "\n",
    "hF, mHA = plt.subplots(nrows = numRowsFig, ncols = numColsFig, figsize = (30, 60))\n",
    "\n",
    "kk = 0\n",
    "for ii in range(featuresFirstIdx, numCols):\n",
    "    sns.scatterplot(data = dfData, x = 'Age', y = dfData.columns[ii],hue = 'Cancer', ax = mHA.flat[kk]) #<! mA.flat[kk] Allows linear indexing for non 1D arrays\n",
    "    kk += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though no feature can discriminate the 2 groups in higher dimension a classifier might be able to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification / Anomaly Detection\n",
    "\n",
    "In this section we'll apply a classifier on the data using the `LightGBM` package which is one of the top 3 decision trees ensemble packages.  \n",
    "Usually for tabular data ensemble of decision trees is the most effective algorithm to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be0bb58de34efdc896882b24f079eecc07771980f2877d3d2e7074352c003269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
