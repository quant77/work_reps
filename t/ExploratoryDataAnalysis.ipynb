{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CyVers](https://i.imgur.com/yyhmZET.png)](https://www.cyvers.ai/)\n",
    "\n",
    "# BlockChain Attack Data Set - Exploratory Data Analysis (EDA)\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital Royi@cyvers.ai\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 30/06/2022 | Royi Avital | First version                                                      |\n",
    "| 0.2.000 | 25/07/2022 | Royi Avital | Added model selection and visualization of features                |\n",
    "| 0.3.000 | 31/07/2022 | Royi Avital | Added a view of feature importance (Should be moved to a funciton) |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Misc\n",
    "import datetime\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# EDA Tools\n",
    "import ppscore as pps #<! See https://github.com/8080labs/ppscore -> pip install git+https://github.com/8080labs/ppscore.git\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedGroupKFold, train_test_split\n",
    "\n",
    "# Ensemble Engines\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "from ipywidgets import interact, Dropdown, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FOLDER_NAME    = 'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet0'\n",
    "DATA_FILE_EXT       = 'csv'\n",
    "\n",
    "PROJECT_DIR_NAME = 'CyVers' #<! Royi: Anton, don't change it, it should be a team constant\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after / before `CyVers`\n",
    "\n",
    "# Feature extractors constants\n",
    "\n",
    "TRAIN_BY_TSX    = 1\n",
    "TRAIN_BY_FILES  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CyVers Packages\n",
    "from DataSetsAuxFun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "# Features Analysis\n",
    "numCrossValPps = 4\n",
    "\n",
    "# Training\n",
    "trainMode = TRAIN_BY_FILES\n",
    "testSetRatio = 1 / 3\n",
    "numKFolds = 3\n",
    "gridSearchScore = 'f1' #<! Use strings from `sklearn.metrics.get_scorer_names()`\n",
    "gridSearchScore = 'recall' #<! We need to have better PD\n",
    "\n",
    "# Amount USD Outlier threshold\n",
    "amountUsdOutlierThr = 1e9\n",
    "\n",
    "randomState = 42\n",
    "\n",
    "lSlctedFeaturesRaw    = ['Amount', 'Currency', 'Currency Type', 'Amount [USD]', 'Receiver Type', 'Gas Price', 'Gas Limit', 'Gas Used' ]#lSlctedFeaturesRaw    = ['Amount', 'Currency', 'Amount [USD]', 'Receiver Type']\n",
    "lSlctedFeaturesCalc   = [enumObj.name for enumObj in FeatureName if ((enumObj is not FeatureName.TIME_MAX) and (enumObj is not FeatureName.TIME_MIN))]\n",
    "lSlctdFeatures        = lSlctedFeaturesRaw + lSlctedFeaturesCalc\n",
    "lCatFeatures          = ['Currency', 'Currency Type', 'Receiver Type']#lCatFeatures          = ['Currency', 'Receiver Type']\n",
    "# lFeaturesRemove       = [FeatureName.TIME_MAX.name, FeatureName.TIME_MIN.name] #<! Auxiliary features to be removed before processing\n",
    "\n",
    "timeColStr = 'Block Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "lCsvFile = ExtractCsvFiles(dataSetRotoDir, folderNamePattern = DATA_FOLDER_PATTERN)\n",
    "print(f'The number of file found: {len(lCsvFile)}')\n",
    "\n",
    "lCsvColName     = ['Transaction ID', 'Block Time', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Receiver Type', 'Amount', 'Currency', 'Currency Hash', 'Currency Type', 'Amount [USD]', 'Gas Price', 'Gas Limit', 'Gas Used', 'Gas Predicted', 'Balance In', 'Balance Out', 'Label', 'Risk Level']\n",
    "lCsvColNameFlag = [True,              True,         True,               True,        True,          True,            True,     True,       True,            True,            True,           True,        True,        True,       True,            True,         True,          False,   False]  #<! Flags if a column is a must to have\n",
    "\n",
    "# dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "#dfData, dAssetFile = LoadCsvFilesDf(lCsvFile, baseFoldePath = '')\n",
    "dfData, dAssetFile =  LoadCsvFilesDf(lCsvFile, baseFoldePath = '', lColName = lCsvColName, lColFlag =  lCsvColNameFlag)\n",
    "\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f\"The number of rows (Samples): {numRows}, The number of columns: {numCols}, number of unique sender id's: {dfData['Sender ID'].unique().shape}\")\n",
    "print(f'The data list of columns is: {dfData.columns} with {len(dfData.columns)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time data into Pandas format\n",
    "dfData[timeColStr] = pd.to_datetime(dfData[timeColStr], infer_datetime_format = 'True') #<! Stable time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by transaction date\n",
    "dfData.sort_values(timeColStr, inplace = True)\n",
    "# dfData.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meet the data\n",
    "dfData.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about the Data Before Pre Processing\n",
    "\n",
    "1. See the labeled cases.\n",
    "2. Count the Labels data.\n",
    "3. Number of unique assets.\n",
    "4. Pandas' `info()` and `describe()`.\n",
    "\n",
    "After this phase, the data is _read only_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at attack cases\n",
    "dfData.loc[dfData['Label'] == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance of labels: Highly imbalanced data (As expected)\n",
    "dfData['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique `Sender ID` (Assets) we have.\n",
    "# It should match the number of files, if not, it either means we have duplications or teh same asset was attacked twice.\n",
    "len(dfData['Sender ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing\n",
    "\n",
    "1. Remove invalid data.\n",
    "2. Remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting invalid `Amount USD`\n",
    "\n",
    "dsInValidTrnsUsd = ((dfData['Amount [USD]'] == 0) | (dfData['Amount [USD]'].isna()) | (dfData['Amount [USD]'] == ''))\n",
    "\n",
    "print(f'Number of invalid `Amount [USD]`: {dsInValidTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid data\n",
    "dfData.drop(dfData.index[dsInValidTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Outliers in the `Amount [USD]`\n",
    "\n",
    "dsOutlierTrnsUsd = ((dfData['Amount [USD]'] >= amountUsdOutlierThr) | (dfData['Amount [USD]'] <= 0))\n",
    "\n",
    "print(f'Number of outliers `Amount [USD]`: {dsOutlierTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "dfData.drop(dfData.index[dsOutlierTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on this is the data to work with\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the Data\n",
    "\n",
    "Basic infomration about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Information\n",
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Data Description\n",
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each hacker attacked\n",
    "dsAttacksAsset = dfData[dfData['Label'] == 1]['Receiver ID'].value_counts()\n",
    "\n",
    "print(f'There are {dsAttacksAsset.shape[0]} Attackers')\n",
    "print(dsAttacksAsset.head(len(dsAttacksAsset))) #<! Last ones should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF, hA = plt.subplots(figsize = (20, 10)) # \n",
    "sns.countplot(dsAttacksAsset, ax = hA)\n",
    "hA.set_title('Number of Attacks per Attacker')\n",
    "hA.set_xlabel('Number of Executed Attacks')\n",
    "hA.set_ylabel('Number of Attackers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each asset was attacked?\n",
    "dsSenderCount = dfData[dfData['Label'] == 1]['Sender ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF, hA = plt.subplots(figsize = (20, 10)) # TODO: Display an histogram (How many assets were attacked 1, 2, ...)\n",
    "sns.countplot(dsSenderCount, ax = hA)\n",
    "hA.set_title('Number of Attacks per Asset')\n",
    "hA.set_xlabel('Number of Executed Attacks')\n",
    "hA.set_ylabel('Number of Assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different assets each attacker attacked? How many times per asset?\n",
    "dsAttacksIdAttacker = dfData[dfData['Label'] == 1].groupby(['Receiver ID', 'Sender ID'])['Transaction ID'].count().reset_index(name = 'Number of Attacks')  \n",
    "dsAttacksIdAttacker.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Pandas Extension (Don't change the Index from now on!)\n",
    "numGrps = dfData.GrpBySender.numGrps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SASA vs. SAMA Cases\n",
    "\n",
    "Definitions:\n",
    "\n",
    " * SASA:\n",
    " * SAMA:\n",
    "\n",
    "**Remark**: Move to:\n",
    "\n",
    "SASASW - Single Asset, Single   Attacks, Single   Wallets  \n",
    "SAMASW - Single Asset, Multiple Attacks, Single   Wallets (SAMA)  \n",
    "SAMAMW - Single Asset, Multiple Attacks, Multiple Wallets (SAMA)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Attack Type\n",
    "# !!! The function `CalcAttackType()` uses the Pandas extension, hence it should be initialized before!\n",
    "dsAttackType, dfAttackType = CalcAttackType(dfData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an Histogram of the Attack Types\n",
    "hF, hA = plt.subplots(figsize = (16, 12))\n",
    "sns.countplot(x = dfAttackType['Attack Type'], ax = hA)\n",
    "hA.set_title('Number of Cases (Attacks) by Attack Types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section adds features and engineers them.  \n",
    "Most features work on the `Sender ID` group.\n",
    "\n",
    "#### Amount Based Features:\n",
    "\n",
    "1. The STD of the user vs the average STD of all other users of the asset.\n",
    "2. The Median of the user vs the average STD of all other users of the asset.\n",
    "3. \n",
    "\n",
    "#### Date Based Features\n",
    "\n",
    "1. The day of the week.\n",
    "2. Weekend.\n",
    "3. Hour of the day.\n",
    "4. STD fo the time difference of the user vs. the avergae of all other users.\n",
    "5. Median fo the time difference of the user vs. the avergae of all other users.\n",
    "\n",
    "**Remark**: For wallets with a lot of activity we need to analyze the \"activity hours\" and profile it.\n",
    "\n",
    "\n",
    "The features are:\n",
    "\n",
    " 1. Day of the Week.\n",
    "\n",
    "Remarks:\n",
    "\n",
    " *  Features x-y are time / frequency related.\n",
    " *  Features z-t are trasnaction realted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process\n",
    "\n",
    "dfGbs = dfData.GrpBySender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features per Asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based\n",
    "\n",
    "sum_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s          = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s        = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s         = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "coint_c         = dfGbs.AggBySender(colName = dfGbs.currencyColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_COIN_TYPE)\n",
    "receiver_type_c = dfGbs.AggBySender(colName = dfGbs.receiverTypeColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_RECEIVER_TYPE)\n",
    "\n",
    "gas_pr_mean     = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_lim_mean    = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_used_mean   = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_pr_std      = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_lim_std     = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_used_std    = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_pr_med      = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_lim_med     = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_used_med    = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "\n",
    "\n",
    "dfData[FeatureName.AMOUNT_SUM_ASSET.name]          = sum_s\n",
    "dfData[FeatureName.AMOUNT_MEAN_ASSET.name]         = mean_s\n",
    "dfData[FeatureName.AMOUNT_STD_ASSET.name]          = std_s\n",
    "dfData[FeatureName.AMOUNT_VAR_ASSET.name]          = var_s\n",
    "dfData[FeatureName.AMOUNT_MEDIAN_ASSET.name]       = median_s\n",
    "dfData[FeatureName.AMOUNT_MIN_ASSET.name]          = min_s\n",
    "dfData[FeatureName.AMOUNT_MAX_ASSET.name]          = max_s\n",
    "dfData[FeatureName.TSX_COUNT_ASSET.name]           = count_s\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_ASSET.name]     = coint_c\n",
    "dfData[FeatureName.RECEIVER_TYPE_COUNT_ASSET.name] = receiver_type_c\n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_MEAN_ASSET.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_PRICE_STD_ASSET.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_PRICE_MEDIAN_ASSET.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_LIMIT_MEAN_ASSET.name] = gas_lim_mean\n",
    "dfData[FeatureName.GAS_LIMIT_STD_ASSET.name] = gas_lim_std\n",
    "dfData[FeatureName.GAS_LIMIT_MEDIAN_ASSET.name] = gas_lim_med\n",
    "\n",
    "dfData[FeatureName.GAS_USED_MEAN_ASSET.name] = gas_used_mean\n",
    "dfData[FeatureName.GAS_USED_STD_ASSET.name] = gas_used_std\n",
    "dfData[FeatureName.GAS_USED_MEDIAN_ASSET.name] = gas_used_med\n",
    "\n",
    "#COIN_TYPE_COUNT_USR                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "td_mean_s   = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_ASSET.name]   = td_mean_s\n",
    "dfData[FeatureName.TIME_DIFF_STD_ASSET.name]    = td_std_s\n",
    "dfData[FeatureName.TIME_DIFF_MEDIAN_ASSET.name] = td_median_s\n",
    "dfData[FeatureName.TIME_DIFF_MIN_ASSET.name]    = td_min_s\n",
    "dfData[FeatureName.TIME_DIFF_MAX_ASSET.name]    = td_max_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based (User)\n",
    "\n",
    "sum_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s          = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s        = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s         = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "coin_c          = dfGbs.AggByReceiver(colName = dfGbs.currencyColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_COIN_TYPE)\n",
    "receiver_type_c = dfGbs.AggByReceiver(colName = dfGbs.receiverTypeColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_RECEIVER_TYPE) #<! Royi: We need to check why is it so important?!?!\n",
    "\n",
    "gas_pr_mean     = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_lim_mean    = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_used_mean   = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "\n",
    "gas_pr_std      = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_lim_std     = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_used_std    = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "\n",
    "gas_pr_med      = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_lim_med     = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_used_med    = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "\n",
    "gas_pr_quant    = dfGbs.dfSubGrpByRec[dfGbs.gasPriceColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "gas_lim_quant   = dfGbs.dfSubGrpByRec[dfGbs.gasLimitColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "gas_used_quant  = dfGbs.dfSubGrpByRec[dfGbs.gasUsedColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "\n",
    "\n",
    "dfData[FeatureName.AMOUNT_SUM_USR.name]          = sum_s\n",
    "dfData[FeatureName.AMOUNT_MEAN_USR.name]         = mean_s\n",
    "dfData[FeatureName.AMOUNT_STD_USR.name]          = std_s\n",
    "dfData[FeatureName.AMOUNT_VAR_USR.name]          = var_s\n",
    "dfData[FeatureName.AMOUNT_MEDIAN_USR.name]       = median_s\n",
    "dfData[FeatureName.AMOUNT_MIN_USR.name]          = min_s\n",
    "dfData[FeatureName.AMOUNT_MAX_USR.name]          = max_s\n",
    "dfData[FeatureName.TSX_COUNT_USR.name]           = count_s\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_USR.name]     = coin_c\n",
    "dfData[FeatureName.RECEIVER_TYPE_COUNT_USR.name] = receiver_type_c    \n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_MEAN_USR.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_PRICE_STD_USR.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_PRICE_MEDIAN_USR.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_LIMIT_MEAN_USR.name] = gas_lim_mean\n",
    "dfData[FeatureName.GAS_LIMIT_STD_USR.name] = gas_lim_std\n",
    "dfData[FeatureName.GAS_LIMIT_MEDIAN_USR.name] = gas_lim_med\n",
    "\n",
    "dfData[FeatureName.GAS_USED_MEAN_USR.name] = gas_used_mean\n",
    "dfData[FeatureName.GAS_USED_STD_USR.name] = gas_used_std\n",
    "dfData[FeatureName.GAS_USED_MEDIAN_USR.name] = gas_used_med\n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_QUANTILE_USR.name] = gas_pr_quant\n",
    "dfData[FeatureName.GAS_LIMIT_QUANTILE_USR.name] = gas_lim_quant\n",
    "dfData[FeatureName.GAS_USED_QUANTILE_USR.name] = gas_used_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based (User)\n",
    "\n",
    "td_mean_s   = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_USR.name]   = td_mean_s\n",
    "dfData[FeatureName.TIME_DIFF_STD_USR.name]    = td_std_s\n",
    "dfData[FeatureName.TIME_DIFF_MEDIAN_USR.name] = td_median_s\n",
    "dfData[FeatureName.TIME_DIFF_MIN_USR.name]    = td_min_s\n",
    "dfData[FeatureName.TIME_DIFF_MAX_USR.name]    = td_max_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Transaction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "dfData[FeatureName.TIME_HOUR.name]    = dfGbs.GetTimeVals(periodTimeType = PeriodTimeType.HOUR_DAY)\n",
    "dfData[FeatureName.TIME_WEEKDAY.name] = dfGbs.GetTimeVals(periodTimeType = PeriodTimeType.DAY_WEEK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio Based Features\n",
    "\n",
    "dfData[FeatureName.AMOUNT_MEAN_RATIO_USR_ASSET.name]    = dfData[FeatureName.AMOUNT_MEAN_USR.name] / dfData[FeatureName.AMOUNT_MEAN_ASSET.name]\n",
    "dfData[FeatureName.AMOUNT_STD_RATIO_USR_ASSET.name]    = dfData[FeatureName.AMOUNT_STD_USR.name] / dfData[FeatureName.AMOUNT_STD_ASSET.name]\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_RATIO_USR_ASSET.name] = dfData[FeatureName.TIME_DIFF_MEAN_USR.name] / dfData[FeatureName.TIME_DIFF_MEAN_ASSET.name]\n",
    "dfData[FeatureName.TIME_DIFF_STD_RATIO_USR_ASSET.name] = dfData[FeatureName.TIME_DIFF_STD_USR.name] / dfData[FeatureName.TIME_DIFF_STD_ASSET.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Based Features\n",
    "\n",
    "dfData[FeatureName.TIME_MAX.name] = dfGbs.AggByReceiver(colName = timeColStr, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "dfData[FeatureName.TIME_MIN.name] = dfGbs.AggByReceiver(colName = timeColStr, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "\n",
    "dfData[FeatureName.TIME_INTERVL_USR.name] = ((dfData[FeatureName.TIME_MAX.name] - dfData[FeatureName.TIME_MIN.name])).dt.total_seconds()\n",
    "\n",
    "# Frequency of the User Transactions\n",
    "dfData[FeatureName.TSX_FREQ_HZ_USR.name] = dfData[FeatureName.TSX_COUNT_USR.name] / dfData[FeatureName.TIME_INTERVL_USR.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gas ratio features(experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratios between the user to the mean of all users.\n",
    "dfData[FeatureName.GAS_PRICE_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_PRICE_MEAN_ASSET.name]\n",
    "dfData[FeatureName.GAS_LIMIT_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_LIMIT_MEAN_USR.name] / dfData[FeatureName.GAS_LIMIT_MEAN_ASSET.name]\n",
    "dfData[FeatureName.GAS_USED_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_USED_MEAN_USR.name] / dfData[FeatureName.GAS_USED_MEAN_ASSET.name] \n",
    "#Gas Price', 'Gas Limit', 'Gas Used'\n",
    "dfData[FeatureName.GAS_PRICE_LIMIT_RATIO.name] = dfData['Gas Price'] / dfData['Gas Limit']\n",
    "dfData[FeatureName.GAS_PRICE_USED_RATIO.name] = dfData['Gas Price'] / dfData['Gas Used']\n",
    "dfData[FeatureName.GAS_USED_LIMIT_RATIO.name] = dfData['Gas Used'] / dfData['Gas Limit'] \n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_LIMIT_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_LIMIT_MEAN_USR.name]\n",
    "dfData[FeatureName.GAS_PRICE_USED_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_USED_MEAN_USR.name]\n",
    "dfData[FeatureName.GAS_USED_LIMIT_RATIO_MEAN.name] = dfData[FeatureName.GAS_USED_MEAN_USR.name] / dfData[FeatureName.GAS_PRICE_MEAN_USR.name] \n",
    "\n",
    "\n",
    "#Compare it to 75 quantile (TSX Gas Price / Quantile(75) of Gas Price).\n",
    "dfData[FeatureName.GAS_PRICE_QUANTILE_RATIO.name] = dfData['Gas Price'] / dfData[FeatureName.GAS_PRICE_QUANTILE_USR.name]\n",
    "dfData[FeatureName.GAS_LIMIT_QUANTILE_RATIO.name] = dfData['Gas Limit'] / dfData[FeatureName.GAS_LIMIT_QUANTILE_USR.name]\n",
    "dfData[FeatureName.GAS_USED_QUANTILE_RATIO.name] =  dfData['Gas Used'] / dfData[FeatureName.GAS_USED_QUANTILE_USR.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature to indicate first transaction\n",
    "dfData[FeatureName.MIN_INDICATOR.name] = 0 ; dfData.loc[dfData[timeColStr] == dfData[FeatureName.TIME_MIN.name], FeatureName.MIN_INDICATOR.name] = 1 \n",
    "### TODO !!! this can be invorrect. it will need a review !!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56\n",
    "#Create features based on the currency of the transactions:\n",
    "# 1. The number of different types of currencies per user. <-- done previously = dfData[FeatureName.COIN_TYPE_COUNT_USR.name]\n",
    "# 2. The average of the number of types of all user for an asset. <-- groupby asset , mean(number of different types of currencies per user)\n",
    "# 3. The ratio between a specific user to the average of the asset. --> 1/2\n",
    "    \n",
    "\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_USR_MEAN_ASSET.name]    = dfGbs.AvgByUserCoinType()\n",
    "dfData[FeatureName.COIN_TYPE_USR_MEAN_ASSET_RATIO.name]  = dfData[FeatureName.COIN_TYPE_COUNT_USR.name] / dfData[FeatureName.COIN_TYPE_COUNT_USR_MEAN_ASSET.name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures     = len(lSlctdFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Scatter of the Features\n",
    "\n",
    "oDropdwon = Dropdown(\n",
    "    options     = lSlctdFeatures,\n",
    "    value       = 'Amount [USD]',\n",
    "    description = 'Select Feature:',\n",
    "    style       = {'description_width' : 'initial'}\n",
    ")\n",
    "\n",
    "interact(lambda yColName: DisplayScatterFeature(dfData, 'Label', yColName, 'Suspicious'), yColName = oDropdwon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Density of the Features\n",
    "\n",
    "oDropdwon = Dropdown(\n",
    "    options     = lSlctdFeatures,\n",
    "    value       = 'Amount [USD]',\n",
    "    description = 'Select Feature:',\n",
    "    style       = {'description_width' : 'initial'}\n",
    ")\n",
    "\n",
    "interact(lambda yColName: DisplayKdeFeature(dfData, yColName, 'Label', 'Suspicious'), yColName = oDropdwon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Pre Processing (For Training Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData_ = dfData.copy(deep=True) ###<<-- I create a copy of data frame for experiment with categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing Data\n",
    "dfData.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "dfData.fillna(0, inplace = True)\n",
    "dfX = dfData[lSlctdFeatures].copy()\n",
    "for catColName in lCatFeatures:\n",
    "    dfX[catColName], _ =  pd.factorize(dfX[catColName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data for Classifier\n",
    "\n",
    "lNumericalFeatures = [featureName for featureName in lSlctdFeatures if featureName not in lCatFeatures]\n",
    "\n",
    "mX = dfX[lNumericalFeatures].to_numpy()\n",
    "mC = dfX[lCatFeatures].to_numpy()\n",
    "vY = dfData['Label'].to_numpy()\n",
    "# Scaling the data\n",
    "hStdScaler = StandardScaler() #<! Don't touch categorial data\n",
    "mX = hStdScaler.fit_transform(mX)\n",
    "mX = np.concatenate((mX, mC), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the PPS Matrix\n",
    "\n",
    "The idea is to see the relationship between the features not by a linear correlation but by the ability to predict them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DF for the PPS analysis\n",
    "dfTmp = dfData[lSlctdFeatures + ['Label']].copy()\n",
    "\n",
    "for featureName in (lCatFeatures + ['Label']):\n",
    "    dfTmp[featureName] = pd.Categorical(dfTmp[featureName])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature PPS - Which featuers are important?\n",
    "\n",
    "# Pay attention, cross validation is K-Fold -> Don't over split the data\n",
    "mPPS = pps.matrix(dfTmp, **{'cross_validation': numCrossValPps, 'random_seed': randomState})[['x', 'y', 'ppscore']].pivot(columns = 'x', index = 'y', values = 'ppscore') #<! We should set `Label` as a categorial variable\n",
    "\n",
    "# Visualization of PPS\n",
    "hF, hA = plt.subplots(figsize = (30, 30))\n",
    "sns.heatmap(mPPS, annot = True, fmt = '.2f', cmap = plt.get_cmap('coolwarm'), cbar = False, vmin = 0, vmax = 1, ax = hA) \n",
    "\n",
    "plt.setp(hA.get_xticklabels(), ha = \"center\", rotation = 45)\n",
    "plt.setp(hA.get_yticklabels(), rotation = 'horizontal')\n",
    "hA.set_title('Predictive Power Score (PPS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation the columns are legit\n",
    "dfX.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, test_size = testSetRatio, random_state = randomState, stratify = vY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbModel = XGBClassifier(use_label_encoder = False)\n",
    "xgbModel.fit(mXTrain, vYTrain)\n",
    "vYPred = xgbModel.predict(mXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayConfusionMatrix(vYTest, vYPred, lClasses = xgbModel.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsScoreSumm = GenClassifierSummaryResults(vYTest, vYPred)\n",
    "dfScoreSummary  = pd.DataFrame(dsScoreSumm, columns = ['Score'])\n",
    "dfScoreSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training by Transactions (K-Fold)\n",
    "hKFoldSplt = StratifiedKFold(n_splits = numKFolds, shuffle = True, random_state = randomState)\n",
    "for vTrinIdx, vTestIdx in hKFoldSplt.split(mX, vY):\n",
    "    mXTrain, mXTest, vYTrain, vYTest = mX[vTrinIdx, :], mX[vTestIdx, :], vY[vTrinIdx], vY[vTestIdx]\n",
    "    xgbModel = XGBClassifier(use_label_encoder = False)\n",
    "    xgbModel.fit(mXTrain, vYTrain)\n",
    "    vYPred = xgbModel.predict(mXTest)\n",
    "    DisplayConfusionMatrix(vYTest, vYPred, lClasses = xgbModel.classes_)\n",
    "    print(GenClassifierSummaryResults(vYTest, vYPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lTotalFeatures = lNumericalFeatures + lCatFeatures\n",
    "len(lTotalFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatures = pd.DataFrame(data = list(zip(lTotalFeatures, xgbModel.feature_importances_)), columns = ['Feature Name', 'Feature Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF, hA = plt.subplots(figsize = (32, 8))\n",
    "sns.barplot(data = dfFeatures, x = 'Feature Name', y = 'Feature Importance', ax = hA)\n",
    "plt.setp(hA.get_xticklabels(), rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing data to match the text indices\n",
    "vTetsIdxDf = dfData.index[vTestIdx]\n",
    "dAttackTypeName = {}\n",
    "for attackTypeEnum in AttackType:\n",
    "    dAttackTypeName[attackTypeEnum.value] = attackTypeEnum.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenClassifierSummaryResultsGrp(vYTest, vYPred, vGrpLabel = dsAttackType[vTetsIdxDf].to_numpy(), dGrpName = dAttackTypeName) #<! Results don't look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training by Files (K-Fold)\n",
    "hKFoldSplt = StratifiedGroupKFold(n_splits = numKFolds, shuffle = True, random_state = randomState)\n",
    "for vTrainIdx, vTestIdx in hKFoldSplt.split(mX, vY, groups = dfData['Sender ID']):\n",
    "    mXTrain, mXTest, vYTrain, vYTest = mX[vTrainIdx, :], mX[vTestIdx, :], vY[vTrainIdx], vY[vTestIdx]\n",
    "    xgbModel = XGBClassifier(use_label_encoder = False)\n",
    "    xgbModel.fit(mXTrain, vYTrain)\n",
    "    vYPred = xgbModel.predict(mXTest)\n",
    "    DisplayConfusionMatrix(vYTest, vYPred, lClasses = xgbModel.classes_)\n",
    "    print(GenClassifierSummaryResults(vYTest, vYPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold training, using categorical variables (EXPERIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### only pd.df approach is working, numpy(dtype=object) didn't work so it is not represented\n",
    "#make sure below lists are defined\n",
    "lNumericalFeatures = [featureName for featureName in lSlctdFeatures if featureName not in lCatFeatures]\n",
    "lTotalFeatures = lNumericalFeatures + lCatFeatures\n",
    "feature_types_ = ['c' if x in lCatFeatures  else 'float' for x in lTotalFeatures]#feature_types_ = ['c' if x in lCatFeatures  else float for x in lTotalFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing Data categorical mine, here dfData_ <-- is used for experiment\n",
    "\n",
    "dfData_.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "dfData_.fillna(0, inplace = True)\n",
    "dfX_ = dfData_[lSlctdFeatures].copy()\n",
    "\n",
    "for catColName in lCatFeatures:\n",
    "    dfX_[catColName] = dfX_[catColName].astype(\"category\", copy = False)\n",
    "hStdScaler = StandardScaler()\n",
    "dfX_[lNumericalFeatures] = hStdScaler.fit_transform(dfX_[lNumericalFeatures])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mX = dfX_[lTotalFeatures]\n",
    "mX.rename(columns = {'Amount [USD]':'Amount USD'}, inplace = True)\n",
    "vY = dfData_['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hKFoldSplt = StratifiedGroupKFold(n_splits = numKFolds, shuffle = True, random_state = randomState)\n",
    "for vTrainIdx, vTestIdx in hKFoldSplt.split(mX, vY, groups = dfData['Sender ID']):\n",
    "    mXTrain, mXTest, vYTrain, vYTest = mX.iloc[vTrainIdx], mX.iloc[vTestIdx], vY.iloc[vTrainIdx], vY.iloc[vTestIdx]\n",
    "    #xgbModel =XGBClassifier(tree_method=\"gpu_hist\", max_depth = 20, feature_names = lTotalFeatures, feature_types = feature_types_, random_state=seedNum, enable_categorical=True) #XGBClassifier(use_label_encoder = False)\n",
    "    xgbModel =XGBClassifier(n_estimators=250, tree_method=\"hist\", max_depth = 20,  random_state=seedNum, enable_categorical=True)\n",
    "    xgbModel.fit(mXTrain, vYTrain)\n",
    "    vYPred = xgbModel.predict(mXTest)\n",
    "    DisplayConfusionMatrix(vYTest, vYPred, lClasses = xgbModel.classes_)\n",
    "    print(GenClassifierSummaryResults(vYTest, vYPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if trainMode == TRAIN_BY_FILES:\n",
    "    hKFoldSplt = StratifiedGroupKFold(n_splits = numKFolds, shuffle = True, random_state = randomState)\n",
    "    gKFoldSplit = hKFoldSplt.split(mX, vY, groups = dfData['Sender ID'])\n",
    "else:\n",
    "    hKFoldSplt = StratifiedKFold(n_splits = numKFolds, shuffle = True, random_state = randomState)\n",
    "    gKFoldSplit = hKFoldSplt.split(mX, vY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skPipeline = Pipeline([('clf', XGBClassifier())])\n",
    "dPipelineParams = {'clf': [XGBClassifier(), LGBMClassifier()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchCv = GridSearchCV(skPipeline, dPipelineParams, scoring = gridSearchScore, cv = hKFoldSplt)\n",
    "\n",
    "if trainMode == TRAIN_BY_FILES:\n",
    "    gridSearchCvF = gridSearchCv.fit(mX, vY, groups = dfData['Sender ID'])\n",
    "else:\n",
    "    gridSearchCvF = gridSearchCv.fit(mX, vY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vYPred = gridSearchCvF.predict(mXTest)\n",
    "DisplayConfusionMatrix(vYTest, vYPred, lClasses = gridSearchCvF.classes_)\n",
    "print(GenClassifierSummaryResults(vYTest, vYPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch and Pipelines combo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skPipeline = Pipeline([('clf', XGBClassifier())])\n",
    "#dPipelineParams =  {'clf': [XGBClassifier(), LGBMClassifier()]}\n",
    "\n",
    "\n",
    "skPipeline = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "\n",
    "dPipelineParams = [ {\"classifier\": [XGBClassifier()],\n",
    "                                   \"classifier__n_estimators\": [10, 50, 100, 250],\n",
    "                                   \"classifier__max_depth\" : [5, 10, 20],\n",
    "                                   \"classifier__tree_method\" : [\"hist\", \"gpu_hist\"]\n",
    "                    },\n",
    "                    {\"classifier\": [LGBMClassifier()],\n",
    "                                   \"classifier__n_estimators\": [10, 50, 100, 250],\n",
    "                                   \"classifier__max_depth\" : [5, 10, 20]\n",
    "                                   #\"classifier__class_weight\": [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "                    },  \n",
    "                    {\"classifier\": [RandomForestClassifier()],\n",
    "                                   \"classifier__n_estimators\": [10, 50, 100, 250],\n",
    "                                   \"classifier__max_depth\" : [5, 10, 20],\n",
    "                                   \"classifier__class_weight\": [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "                    }                            \n",
    "                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########make sure mX, vY are not redefined into dfs(simply skip K-fold training, using categorical variables (EXPERIMENT) part), naming should be later changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchCv = GridSearchCV(skPipeline, dPipelineParams, scoring = gridSearchScore, cv = hKFoldSplt)\n",
    "\n",
    "if trainMode == TRAIN_BY_FILES:\n",
    "    gridSearchCvF = gridSearchCv.fit(mX, vY, groups = dfData['Sender ID'])\n",
    "else:\n",
    "    gridSearchCvF = gridSearchCv.fit(mX, vY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gridSearchCvF.best_estimator_.get_params()[\"classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vYPred = gridSearchCvF.predict(mXTest)\n",
    "DisplayConfusionMatrix(vYTest, vYPred, lClasses = gridSearchCvF.classes_)\n",
    "print(GenClassifierSummaryResults(vYTest, vYPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95ddca318bf123e47b38b5a5b9dcba5a0c9d5dde3556722e5a10703c6b4cbfc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
