{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CyVers](https://i.imgur.com/yyhmZET.png)](https://www.cyvers.ai/)\n",
    "\n",
    "# Verify the CSV Files\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital Royi@cyverse.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | Content / Changes                        |\n",
    "|---------|------------|------------------------------------------|\n",
    "| 0.1.000 | 11/07/2022 | First version                            |\n",
    "| 0.2.000 | 20/07/2022 | Added warnings related to `Amount [USD]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools\n",
    "import numpy as np\n",
    "# import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Misc\n",
    "# import datetime\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# EDA Tools\n",
    "# import ppscore as pps #<! See https://github.com/8080labs/ppscore -> pip install git+https://github.com/8080labs/ppscore.git\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Ensemble Engines\n",
    "# import lightgbm\n",
    "# import xgboost\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "# from ipywidgets import interact, Dropdown, Layout\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FOLDER_NAME    = 'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet0' #<! The '0' is needed in order to process templates as 'DataSet0xx' and not 'AttackDataSet'\n",
    "DATA_FILE_EXT       = 'csv'\n",
    "\n",
    "OUT_FOLDER_NAME = 'TMP'\n",
    "\n",
    "PROJECT_DIR_NAME = 'CyVers'\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after `CyVers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CyVers Packages\n",
    "from DataSetsAuxFun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "timeColLabel        = 'Transaction Time'\n",
    "amountUsdColLabel   = 'Amount [USD]'\n",
    "labelColLabel       = 'Label'\n",
    "\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "verifySingleSenderId    = True\n",
    "addFileNameCol          = True\n",
    "genDoubleAssetsCsvFile  = True\n",
    "genMultipleRecPerAttack = True\n",
    "genAmountUsdOutliers    = True\n",
    "\n",
    "amountUsdOutlierThr = 1e9\n",
    "\n",
    "# Initial value\n",
    "errorFile   = False\n",
    "warningFile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "lCsvFile = ExtractCsvFiles(dataSetRotoDir, folderNamePattern = DATA_FOLDER_PATTERN)\n",
    "print(f'The number of file found: {len(lCsvFile)}')\n",
    "\n",
    "# dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "dfData, dAssetFile = LoadCsvFilesDf(lCsvFile, baseFoldePath = '', verifySingleSenderId = verifySingleSenderId, addFileNameCol = addFileNameCol)\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')\n",
    "print(f'The data list of columns is: {dfData.columns} with {len(dfData.columns)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGrpBySender   = dfData.groupby('Sender ID') #<! Basically per file if verifySingleSenderId = True\n",
    "dfGrpByFileName = dfData.groupby('File Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check `Transaction Time` is valid\n",
    "\n",
    "if pd.to_datetime(dfData[timeColLabel], errors = 'coerce').isnull().any():\n",
    "    print(f'The DF Must have the {timeColLabel} column with a valid date format')\n",
    "    errorFile = True\n",
    "\n",
    "    display(dfData[['Transaction ID', 'File Name']][pd.to_datetime(dfData[timeColLabel], errors = 'coerce').isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of files matches the number of unique `Sender ID`\n",
    "\n",
    "doubleAssets = False\n",
    "\n",
    "numSenderId = len(dfData['Sender ID'].unique())\n",
    "if len(lCsvFile) != numSenderId:\n",
    "    print(f'The number of files: {len(lCsvFile)}, The number of unique \\'Sender ID\\': {numSenderId} which doesn\\'t match')\n",
    "    doubleAssets    = True\n",
    "    errorFile       = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if genDoubleAssetsCsvFile and doubleAssets:\n",
    "    lSenderId = []\n",
    "    lFileName = []\n",
    "    \n",
    "    kk = 0\n",
    "    \n",
    "    for ii, (grpName, dfGroup) in enumerate(dfGrpBySender):\n",
    "        vUniqueFileName = dfGroup['File Name'].unique()\n",
    "        numUniqueFiles  = len(vUniqueFileName)\n",
    "        for jj in range(numUniqueFiles):\n",
    "            if jj == 0:\n",
    "                lSenderId.append(dfGroup['Sender ID'].iloc[0])\n",
    "                lFileName.append(vUniqueFileName[jj])\n",
    "            else:\n",
    "                lFileName[kk] += f', {vUniqueFileName[jj]}'\n",
    "        kk += 1\n",
    "    \n",
    "    dfSenderIDFileName = pd.DataFrame(data = list(zip(lSenderId, lFileName)), columns = ['Sender ID', 'File Name'])\n",
    "    \n",
    "    dfSenderIDFileName.to_csv(os.path.join(OUT_FOLDER_NAME, 'DoubleFiles.csv'))\n",
    "\n",
    "    # Faster way...\n",
    "    # dd = dfData.groupby(['Sender ID', 'File Name'])['Sender ID'].count().reset_index(name='_count')\n",
    "    # dd[dd['Sender ID'].isin(dd['Sender ID'].value_counts().loc[lambda x: x>1].reset_index()['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the cases with multiple `Receiver ID` for the same file\n",
    "multipleReceiverPerHack = False\n",
    "for ii, (grpName, dfGroup) in enumerate(dfGrpByFileName):\n",
    "    if len(dfGroup[dfGroup['Label'] == 1]['Receiver ID'].unique()) > 1:\n",
    "        print('We identified cases where there are multipls `Receiver ID` in a single file')\n",
    "\n",
    "        multipleReceiverPerHack = True\n",
    "        errorFile               = True\n",
    "\n",
    "if genMultipleRecPerAttack and multipleReceiverPerHack:\n",
    "    lFileName   = []\n",
    "    lReceiverId = []\n",
    "\n",
    "    kk = 0\n",
    "\n",
    "    for ii, (grpName, dfGroup) in enumerate(dfGrpByFileName):\n",
    "        dfGroupSubSet   = dfGroup[dfGroup['Label'] == 1]\n",
    "        vReceiverId     = dfGroupSubSet['Receiver ID'].unique()\n",
    "        numRecId        = len(vReceiverId)\n",
    "        for jj in range(numRecId):\n",
    "            if jj == 0:\n",
    "                lFileName.append(dfGroupSubSet['File Name'].iloc[0])\n",
    "                lReceiverId.append(vReceiverId[jj])\n",
    "            else:\n",
    "                lReceiverId[kk] += f', {vReceiverId[jj]}'\n",
    "        kk += 1\n",
    "    \n",
    "    dfRecIDFileName = pd.DataFrame(data = list(zip(lFileName, lReceiverId)), columns = ['File Name', 'Receiver ID'])\n",
    "    \n",
    "    dfRecIDFileName.to_csv(os.path.join(OUT_FOLDER_NAME, 'RecIdFiles.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labeled cases have an invalid `Amount [USD]` (Finder results by https://stackoverflow.com/questions/27159189)\n",
    "\n",
    "dfAttack = dfData.loc[dfData[labelColLabel] == 1]\n",
    "if (dfAttack[amountUsdColLabel].isnull().any()) or ((dfAttack[amountUsdColLabel] == 0).any()) or ((dfAttack[amountUsdColLabel] == '').any()):\n",
    "    print(f'There are labeled cases which have invalid \\'Amount [USD]\\'')\n",
    "    print(f'There are #{dfAttack[amountUsdColLabel].isnull().sum()} labeled cases NAN amount (Might be Empty)')\n",
    "    print(f'There are #{(dfAttack[amountUsdColLabel] == 0).sum()} labeled cases with 0 amount')\n",
    "    numEmptyCells = (dfAttack[amountUsdColLabel] == '').sum()\n",
    "    print(f'There are #{numEmptyCells} labeled cases with empty amount')\n",
    "    \n",
    "    errorFile = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for MAMA Case\n",
    "\n",
    "for grpName, dfGroup in dfGrpBySender:\n",
    "    senderId = dfGroup['Sender ID'].iloc[0]\n",
    "    vHackersId = dfGroup.loc[dfGroup['Label'] == 1]['Receiver ID'].unique()\n",
    "    numUniqueHackers = len(vHackersId)\n",
    "    if numUniqueHackers != 1:\n",
    "        print(f'The file {os.path.basename(dAssetFile[senderId])} contains more than a single hacker (MAMA)')\n",
    "        errorFile = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings - Amount of USD\n",
    "\n",
    "amountUsdOutliers = False\n",
    "dfGrpByFileName = dfData.groupby('File Name')\n",
    "\n",
    "if (dfData[amountUsdColLabel] > amountUsdOutlierThr).any():\n",
    "    print(f'Warning: We identified {(dfData[amountUsdColLabel] > amountUsdOutlierThr).sum()} cases where the transaction `Amount [USD]` is larger than the outlier thereshold: {amountUsdOutlierThr}')\n",
    "\n",
    "    amountUsdOutliers   = True\n",
    "    warningFile         = True\n",
    "\n",
    "\n",
    "if genAmountUsdOutliers and amountUsdOutliers:\n",
    "    lFileName   = []\n",
    "    lTsxId      = []\n",
    "\n",
    "    kk = 0\n",
    "\n",
    "    for ii, (grpName, dfGroup) in enumerate(dfGrpByFileName):\n",
    "        dfGroupSubSet   = dfGroup[dfGroup[amountUsdColLabel] > amountUsdOutlierThr]\n",
    "        if len(dfGroupSubSet) > 0:\n",
    "            vTsxId          = dfGroupSubSet['Transaction ID'].unique() #<! Royi: `unique()` is used here to create a numpy vector basically\n",
    "            numTsxId        = len(vTsxId)\n",
    "            print(f'File Name: {grpName}, Number of cases: {numTsxId}')\n",
    "            for jj in range(numTsxId):\n",
    "                if jj == 0:\n",
    "                    lFileName.append(dfGroupSubSet['File Name'].iloc[0])\n",
    "                    lTsxId.append(vTsxId[jj])\n",
    "                else:\n",
    "                    lTsxId[kk] += f', {vTsxId[jj]}'\n",
    "            kk += 1\n",
    "    \n",
    "    dfRecIDFileName = pd.DataFrame(data = list(zip(lFileName, lTsxId)), columns = ['File Name', 'Transaction ID'])\n",
    "    \n",
    "    dfRecIDFileName.to_csv(os.path.join(OUT_FOLDER_NAME, 'AmountUsdOutlierFiles.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if errorFile is True:\n",
    "    print('The Data Set Is Invalid!!!')\n",
    "\n",
    "if warningFile is True:\n",
    "    print('Theere are some warning in the Data Set!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b091ae1a5f61fa4269f1f2c4a075dfd3ba6d6b741f8802b3932e01e064097caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
