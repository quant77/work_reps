{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules-Based System (RBS) example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of how Iguanas can be used to set up a Rules-Based System (RBS) from scratch. This includes:\n",
    "\n",
    "* Generating new rules\n",
    "* Optimising existing rules\n",
    "* Combining these rules and removing those which are unnecessary\n",
    "* Setting up and optimising the RBS pipeline\n",
    "* Testing the optimised RBS pipeline on a test set\n",
    "\n",
    "In this example, we'll be creating an RBS for a **transaction fraud use case** (i.e. identifying potentially fraudulent transactions). The metric that we'll optimising for will be the **F1 Score**, and we'll just be focusing on **rules to capture fraudulent behaviour** (rather than also including rules which capture good behaviour, which is a relevant methodology to use too)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run, you'll need the following:\n",
    "\n",
    "* A raw, labelled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Read/process data](#ReadProcessData)\n",
    "2. [Rule Generation](#RuleGeneration)\n",
    "3. [Rule Optimisation](#RuleOptimisation)\n",
    "4. [Combine rules and remove those which are unnecessary](#CombineRules)\n",
    "5. [Set up the RBS Pipeline](#SetUpPipeline)\n",
    "6. [Optimise the RBS Pipeline](#OptimiseThePipeline)\n",
    "7. [Filter rules for the optimised RBS Pipeline](#FilterRulesForPipeline)\n",
    "8. [Apply the optimised RBS Pipeline to the test set](#ApplyPipeline)\n",
    "9. [Convert generated rule conditions to system-ready](#ConvertGenToSys)\n",
    "10. [Our final rule set and RBS Pipeline](#FinalRuleSet)\n",
    "11. [There's an easier (and better) way!](#BetterWay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iguanas.rule_generation import RuleGeneratorDT\n",
    "from iguanas.rule_optimisation import BayesianOptimiser\n",
    "from iguanas.metrics.classification import FScore, Precision\n",
    "from iguanas.metrics.pairwise import JaccardSimilarity\n",
    "from iguanas.rules import Rules, ConvertProcessedConditionsToGeneral, ReturnMappings\n",
    "from iguanas.correlation_reduction import AgglomerativeClusteringReducer\n",
    "from iguanas.rule_selection import SimpleFilter, GreedyFilter, CorrelatedFilter\n",
    "from iguanas.rbs import RBSPipeline, RBSOptimiser\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_FOLDER_NAME    = 'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet0'\n",
    "DATA_FILE_EXT       = 'csv'\n",
    "\n",
    "PROJECT_DIR_NAME = 'CyVers' #<! Royi: Anton, don't change it, it should be a team constant\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after / before `CyVers`\n",
    "TRAIN_BY_TSX    = 1\n",
    "TRAIN_BY_FILES  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSetsAuxFun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "# Features Analysis\n",
    "numCrossValPps = 4\n",
    "\n",
    "# Training\n",
    "trainMode = TRAIN_BY_FILES\n",
    "testSetRatio = 1 / 3\n",
    "numKFolds = 3\n",
    "gridSearchScore = 'f1' #<! Use strings from `sklearn.metrics.get_scorer_names()`\n",
    "gridSearchScore = 'recall' #<! We need to have better PD\n",
    "\n",
    "# Amount USD Outlier threshold\n",
    "amountUsdOutlierThr = 1e9\n",
    "\n",
    "randomState = 42\n",
    "\n",
    "lSlctedFeaturesRaw    = ['Amount', 'Currency', 'Currency Type', 'Amount [USD]', 'Receiver Type', 'Gas Price', 'Gas Limit', 'Gas Used' ]#lSlctedFeaturesRaw    = ['Amount', 'Currency', 'Amount [USD]', 'Receiver Type']\n",
    "lSlctedFeaturesCalc   = [enumObj.name for enumObj in FeatureName if ((enumObj is not FeatureName.TIME_MAX) and (enumObj is not FeatureName.TIME_MIN))]\n",
    "lSlctdFeatures        = lSlctedFeaturesRaw + lSlctedFeaturesCalc\n",
    "lCatFeatures          = ['Currency', 'Currency Type', 'Receiver Type']#lCatFeatures          = ['Currency', 'Receiver Type']\n",
    "# lFeaturesRemove       = [FeatureName.TIME_MAX.name, FeatureName.TIME_MIN.name] #<! Auxiliary features to be removed before processing\n",
    "\n",
    "timeColStr = 'Block Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of file found: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\Desktop\\CyVers\\SolidusBlindTest\\DataSetsAuxFun.py:89: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfCurrData = pd.read_csv(os.path.join(baseFoldePath, lCsvFileName[ii]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows (Samples): 1845647, The number of columns: 19, number of unique sender id's: (328,)\n",
      "The data list of columns is: Index(['Transaction ID', 'Transaction Time', 'Block Time', 'Sender ID',\n",
      "       'Receiver ID', 'Receiver Type', 'Amount', 'Currency', 'Currency Hash',\n",
      "       'Currency Type', 'Amount [USD]', 'Gas Price', 'Gas Limit', 'Gas Used',\n",
      "       'Gas Predicted', 'Balance In', 'Balance Out', 'Label', 'Risk Level'],\n",
      "      dtype='object') with 19 columns\n"
     ]
    }
   ],
   "source": [
    "# Loading / Generating Data\n",
    "lCsvFile = ExtractCsvFiles(dataSetRotoDir, folderNamePattern = DATA_FOLDER_PATTERN)\n",
    "print(f'The number of file found: {len(lCsvFile)}')\n",
    "\n",
    "lCsvColName     = ['Transaction ID', 'Block Time', 'Transaction Time', 'Sender ID', 'Receiver ID', 'Receiver Type', 'Amount', 'Currency', 'Currency Hash', 'Currency Type', 'Amount [USD]', 'Gas Price', 'Gas Limit', 'Gas Used', 'Gas Predicted', 'Balance In', 'Balance Out', 'Label', 'Risk Level']\n",
    "lCsvColNameFlag = [True,              True,         True,               True,        True,          True,            True,     True,       True,            True,            True,           True,        True,        True,       True,            True,         True,          False,   False]  #<! Flags if a column is a must to have\n",
    "\n",
    "# dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "#dfData, dAssetFile = LoadCsvFilesDf(lCsvFile, baseFoldePath = '')\n",
    "dfData, dAssetFile =  LoadCsvFilesDf(lCsvFile, baseFoldePath = '', lColName = lCsvColName, lColFlag =  lCsvColNameFlag)\n",
    "\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f\"The number of rows (Samples): {numRows}, The number of columns: {numCols}, number of unique sender id's: {dfData['Sender ID'].unique().shape}\")\n",
    "print(f'The data list of columns is: {dfData.columns} with {len(dfData.columns)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData[timeColStr] = pd.to_datetime(dfData[timeColStr], infer_datetime_format = 'True') #<! Stable time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by transaction date\n",
    "dfData.sort_values(timeColStr, inplace = True)\n",
    "# dfData.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid `Amount [USD]`: 163887\n"
     ]
    }
   ],
   "source": [
    "# Detecting invalid `Amount USD`\n",
    "\n",
    "dsInValidTrnsUsd = ((dfData['Amount [USD]'] == 0) | (dfData['Amount [USD]'].isna()) | (dfData['Amount [USD]'] == ''))\n",
    "\n",
    "print(f'Number of invalid `Amount [USD]`: {dsInValidTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid data\n",
    "dfData.drop(dfData.index[dsInValidTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers `Amount [USD]`: 0\n"
     ]
    }
   ],
   "source": [
    "# Detecting Outliers in the `Amount [USD]`\n",
    "\n",
    "dsOutlierTrnsUsd = ((dfData['Amount [USD]'] >= amountUsdOutlierThr) | (dfData['Amount [USD]'] <= 0))\n",
    "\n",
    "print(f'Number of outliers `Amount [USD]`: {dsOutlierTrnsUsd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "dfData.drop(dfData.index[dsOutlierTrnsUsd], inplace = True) #<! Royi: Should we do a reset index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows (Samples): 1681760, The number of columns: 19\n"
     ]
    }
   ],
   "source": [
    "# From now on this is the data to work with\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f'The number of rows (Samples): {numRows}, The number of columns: {numCols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numGrps = dfData.GrpBySender.numGrps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGbs = dfData.GrpBySender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based\n",
    "\n",
    "sum_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s          = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s        = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s         = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s           = dfGbs.AggBySender(colName = dfGbs.amountUSDColLabel, grpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "coint_c         = dfGbs.AggBySender(colName = dfGbs.currencyColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_COIN_TYPE)\n",
    "receiver_type_c = dfGbs.AggBySender(colName = dfGbs.receiverTypeColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_RECEIVER_TYPE)\n",
    "\n",
    "gas_pr_mean     = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_lim_mean    = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_used_mean   = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_pr_std      = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_lim_std     = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_used_std    = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_pr_med      = dfGbs.AggBySender(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_lim_med     = dfGbs.AggBySender(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_used_med    = dfGbs.AggBySender(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "\n",
    "\n",
    "dfData[FeatureName.AMOUNT_SUM_ASSET.name]          = sum_s\n",
    "dfData[FeatureName.AMOUNT_MEAN_ASSET.name]         = mean_s\n",
    "dfData[FeatureName.AMOUNT_STD_ASSET.name]          = std_s\n",
    "dfData[FeatureName.AMOUNT_VAR_ASSET.name]          = var_s\n",
    "dfData[FeatureName.AMOUNT_MEDIAN_ASSET.name]       = median_s\n",
    "dfData[FeatureName.AMOUNT_MIN_ASSET.name]          = min_s\n",
    "dfData[FeatureName.AMOUNT_MAX_ASSET.name]          = max_s\n",
    "dfData[FeatureName.TSX_COUNT_ASSET.name]           = count_s\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_ASSET.name]     = coint_c\n",
    "dfData[FeatureName.RECEIVER_TYPE_COUNT_ASSET.name] = receiver_type_c\n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_MEAN_ASSET.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_PRICE_STD_ASSET.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_PRICE_MEDIAN_ASSET.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_LIMIT_MEAN_ASSET.name] = gas_lim_mean\n",
    "dfData[FeatureName.GAS_LIMIT_STD_ASSET.name] = gas_lim_std\n",
    "dfData[FeatureName.GAS_LIMIT_MEDIAN_ASSET.name] = gas_lim_med\n",
    "\n",
    "dfData[FeatureName.GAS_USED_MEAN_ASSET.name] = gas_used_mean\n",
    "dfData[FeatureName.GAS_USED_STD_ASSET.name] = gas_used_std\n",
    "dfData[FeatureName.GAS_USED_MEDIAN_ASSET.name] = gas_used_med\n",
    "\n",
    "#COIN_TYPE_COUNT_USR                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "td_mean_s   = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggBySender(colName = dfGbs.timeDiffAssetColLabel, grpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_ASSET.name]   = td_mean_s\n",
    "dfData[FeatureName.TIME_DIFF_STD_ASSET.name]    = td_std_s\n",
    "dfData[FeatureName.TIME_DIFF_MEDIAN_ASSET.name] = td_median_s\n",
    "dfData[FeatureName.TIME_DIFF_MIN_ASSET.name]    = td_min_s\n",
    "dfData[FeatureName.TIME_DIFF_MAX_ASSET.name]    = td_max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Amount Based (User)\n",
    "\n",
    "sum_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_SUM)\n",
    "mean_s          = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "std_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "var_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_VAR)\n",
    "median_s        = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "count_s         = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_COUNT)\n",
    "min_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "max_s           = dfGbs.AggByReceiver(colName = dfGbs.amountUSDColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "coin_c          = dfGbs.AggByReceiver(colName = dfGbs.currencyColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_COIN_TYPE)\n",
    "receiver_type_c = dfGbs.AggByReceiver(colName = dfGbs.receiverTypeColLabel, grpLabel = None, calcType = CalcType.TYPE_COUNT_RECEIVER_TYPE) #<! Royi: We need to check why is it so important?!?!\n",
    "\n",
    "gas_pr_mean     = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_lim_mean    = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "gas_used_mean   = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEAN)\n",
    "\n",
    "gas_pr_std      = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_lim_std     = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "gas_used_std    = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_STD)\n",
    "\n",
    "gas_pr_med      = dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_lim_med     = dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "gas_used_med    = dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_MEDIAN)\n",
    "\n",
    "gas_pr_quant    = dfGbs.dfSubGrpByRec[dfGbs.gasPriceColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasPriceColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "gas_lim_quant   = dfGbs.dfSubGrpByRec[dfGbs.gasLimitColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasLimitColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "gas_used_quant  = dfGbs.dfSubGrpByRec[dfGbs.gasUsedColLabel].transform('quantile' ,q =0.75)#dfGbs.AggByReceiver(colName = dfGbs.gasUsedColLabel, grpLabel = None, calcType = CalcType.TYPE_PCTILE)\n",
    "\n",
    "\n",
    "dfData[FeatureName.AMOUNT_SUM_USR.name]          = sum_s\n",
    "dfData[FeatureName.AMOUNT_MEAN_USR.name]         = mean_s\n",
    "dfData[FeatureName.AMOUNT_STD_USR.name]          = std_s\n",
    "dfData[FeatureName.AMOUNT_VAR_USR.name]          = var_s\n",
    "dfData[FeatureName.AMOUNT_MEDIAN_USR.name]       = median_s\n",
    "dfData[FeatureName.AMOUNT_MIN_USR.name]          = min_s\n",
    "dfData[FeatureName.AMOUNT_MAX_USR.name]          = max_s\n",
    "dfData[FeatureName.TSX_COUNT_USR.name]           = count_s\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_USR.name]     = coin_c\n",
    "dfData[FeatureName.RECEIVER_TYPE_COUNT_USR.name] = receiver_type_c    \n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_MEAN_USR.name] = gas_pr_mean\n",
    "dfData[FeatureName.GAS_PRICE_STD_USR.name] = gas_pr_std\n",
    "dfData[FeatureName.GAS_PRICE_MEDIAN_USR.name] = gas_pr_med\n",
    "\n",
    "dfData[FeatureName.GAS_LIMIT_MEAN_USR.name] = gas_lim_mean\n",
    "dfData[FeatureName.GAS_LIMIT_STD_USR.name] = gas_lim_std\n",
    "dfData[FeatureName.GAS_LIMIT_MEDIAN_USR.name] = gas_lim_med\n",
    "\n",
    "dfData[FeatureName.GAS_USED_MEAN_USR.name] = gas_used_mean\n",
    "dfData[FeatureName.GAS_USED_STD_USR.name] = gas_used_std\n",
    "dfData[FeatureName.GAS_USED_MEDIAN_USR.name] = gas_used_med\n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_QUANTILE_USR.name] = gas_pr_quant\n",
    "dfData[FeatureName.GAS_LIMIT_QUANTILE_USR.name] = gas_lim_quant\n",
    "dfData[FeatureName.GAS_USED_QUANTILE_USR.name] = gas_used_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based (User)\n",
    "\n",
    "td_mean_s   = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEAN)\n",
    "td_std_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_STD)\n",
    "td_median_s = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MEDIAN)\n",
    "td_min_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MIN)\n",
    "td_max_s    = dfGbs.AggByReceiver(colName = dfGbs.timeDiffUserColLabel, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_TIME_DIFF_MAX)\n",
    "\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_USR.name]   = td_mean_s\n",
    "dfData[FeatureName.TIME_DIFF_STD_USR.name]    = td_std_s\n",
    "dfData[FeatureName.TIME_DIFF_MEDIAN_USR.name] = td_median_s\n",
    "dfData[FeatureName.TIME_DIFF_MIN_USR.name]    = td_min_s\n",
    "dfData[FeatureName.TIME_DIFF_MAX_USR.name]    = td_max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - Time Based\n",
    "\n",
    "dfData[FeatureName.TIME_HOUR.name]    = dfGbs.GetTimeVals(periodTimeType = PeriodTimeType.HOUR_DAY)\n",
    "dfData[FeatureName.TIME_WEEKDAY.name] = dfGbs.GetTimeVals(periodTimeType = PeriodTimeType.DAY_WEEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio Based Features\n",
    "\n",
    "dfData[FeatureName.AMOUNT_MEAN_RATIO_USR_ASSET.name]    = dfData[FeatureName.AMOUNT_MEAN_USR.name] / dfData[FeatureName.AMOUNT_MEAN_ASSET.name]\n",
    "dfData[FeatureName.AMOUNT_STD_RATIO_USR_ASSET.name]    = dfData[FeatureName.AMOUNT_STD_USR.name] / dfData[FeatureName.AMOUNT_STD_ASSET.name]\n",
    "dfData[FeatureName.TIME_DIFF_MEAN_RATIO_USR_ASSET.name] = dfData[FeatureName.TIME_DIFF_MEAN_USR.name] / dfData[FeatureName.TIME_DIFF_MEAN_ASSET.name]\n",
    "dfData[FeatureName.TIME_DIFF_STD_RATIO_USR_ASSET.name] = dfData[FeatureName.TIME_DIFF_STD_USR.name] / dfData[FeatureName.TIME_DIFF_STD_ASSET.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Based Features\n",
    "\n",
    "dfData[FeatureName.TIME_MAX.name] = dfGbs.AggByReceiver(colName = timeColStr, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MAX)\n",
    "dfData[FeatureName.TIME_MIN.name] = dfGbs.AggByReceiver(colName = timeColStr, grpLabel = None, subGrpLabel = None, calcType = CalcType.TYPE_MIN)\n",
    "\n",
    "dfData[FeatureName.TIME_INTERVL_USR.name] = ((dfData[FeatureName.TIME_MAX.name] - dfData[FeatureName.TIME_MIN.name])).dt.total_seconds()\n",
    "\n",
    "# Frequency of the User Transactions\n",
    "dfData[FeatureName.TSX_FREQ_HZ_USR.name] = dfData[FeatureName.TSX_COUNT_USR.name] / dfData[FeatureName.TIME_INTERVL_USR.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratios between the user to the mean of all users.\n",
    "dfData[FeatureName.GAS_PRICE_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_PRICE_MEAN_ASSET.name]\n",
    "dfData[FeatureName.GAS_LIMIT_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_LIMIT_MEAN_USR.name] / dfData[FeatureName.GAS_LIMIT_MEAN_ASSET.name]\n",
    "dfData[FeatureName.GAS_USED_USR_ASSET_RATIO_MEAN.name] = dfData[FeatureName.GAS_USED_MEAN_USR.name] / dfData[FeatureName.GAS_USED_MEAN_ASSET.name] \n",
    "#Gas Price', 'Gas Limit', 'Gas Used'\n",
    "dfData[FeatureName.GAS_PRICE_LIMIT_RATIO.name] = dfData['Gas Price'] / dfData['Gas Limit']\n",
    "dfData[FeatureName.GAS_PRICE_USED_RATIO.name] = dfData['Gas Price'] / dfData['Gas Used']\n",
    "dfData[FeatureName.GAS_USED_LIMIT_RATIO.name] = dfData['Gas Used'] / dfData['Gas Limit'] \n",
    "\n",
    "dfData[FeatureName.GAS_PRICE_LIMIT_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_LIMIT_MEAN_USR.name]\n",
    "dfData[FeatureName.GAS_PRICE_USED_RATIO_MEAN.name] = dfData[FeatureName.GAS_PRICE_MEAN_USR.name] / dfData[FeatureName.GAS_USED_MEAN_USR.name]\n",
    "dfData[FeatureName.GAS_USED_LIMIT_RATIO_MEAN.name] = dfData[FeatureName.GAS_USED_MEAN_USR.name] / dfData[FeatureName.GAS_PRICE_MEAN_USR.name] \n",
    "\n",
    "\n",
    "#Compare it to 75 quantile (TSX Gas Price / Quantile(75) of Gas Price).\n",
    "dfData[FeatureName.GAS_PRICE_QUANTILE_RATIO.name] = dfData['Gas Price'] / dfData[FeatureName.GAS_PRICE_QUANTILE_USR.name]\n",
    "dfData[FeatureName.GAS_LIMIT_QUANTILE_RATIO.name] = dfData['Gas Limit'] / dfData[FeatureName.GAS_LIMIT_QUANTILE_USR.name]\n",
    "dfData[FeatureName.GAS_USED_QUANTILE_RATIO.name] =  dfData['Gas Used'] / dfData[FeatureName.GAS_USED_QUANTILE_USR.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature to indicate first transaction\n",
    "dfData[FeatureName.MIN_INDICATOR.name] = 0 ; dfData.loc[dfData[timeColStr] == dfData[FeatureName.TIME_MIN.name], FeatureName.MIN_INDICATOR.name] = 1 \n",
    "### TODO !!! this can be invorrect. it will need a review !!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56\n",
    "#Create features based on the currency of the transactions:\n",
    "# 1. The number of different types of currencies per user. <-- done previously = dfData[FeatureName.COIN_TYPE_COUNT_USR.name]\n",
    "# 2. The average of the number of types of all user for an asset. <-- groupby asset , mean(number of different types of currencies per user)\n",
    "# 3. The ratio between a specific user to the average of the asset. --> 1/2\n",
    "    \n",
    "\n",
    "dfData[FeatureName.COIN_TYPE_COUNT_USR_MEAN_ASSET.name]    = dfGbs.AvgByUserCoinType()\n",
    "dfData[FeatureName.COIN_TYPE_USR_MEAN_ASSET_RATIO.name]  = dfData[FeatureName.COIN_TYPE_COUNT_USR.name] / dfData[FeatureName.COIN_TYPE_COUNT_USR_MEAN_ASSET.name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData_ = dfData.copy(deep=True) ###<<-- I create a copy of data frame for experiment with categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sfs = [\n",
    "    #'Amount',\n",
    " #'Gas Price',\n",
    " #'Gas Used',\n",
    " 'AMOUNT_SUM_USR',\n",
    " 'AMOUNT_MEAN_ASSET',\n",
    " 'AMOUNT_STD_USR',\n",
    " 'AMOUNT_VAR_USR',\n",
    " 'AMOUNT_MIN_ASSET',\n",
    " 'AMOUNT_MIN_USR',\n",
    " 'AMOUNT_MAX_USR',\n",
    " 'TIME_DIFF_MEAN_USR',\n",
    " 'TIME_DIFF_STD_USR',\n",
    " 'TIME_DIFF_MEDIAN_USR',\n",
    " 'TIME_DIFF_MIN_ASSET',\n",
    " 'TIME_DIFF_MIN_USR',\n",
    " 'TIME_DIFF_MAX_ASSET',\n",
    " 'TIME_DIFF_MAX_USR',\n",
    " 'COIN_TYPE_USR_MEAN_ASSET_RATIO',\n",
    " #'COIN_TYPE_COUNT_USR',\n",
    " #'RECEIVER_TYPE_COUNT_USR',\n",
    " #'TIME_HOUR',\n",
    " #'TIME_WEEKDAY',\n",
    " 'TIME_INTERVL_USR',\n",
    " 'TIME_DIFF_STD_RATIO_USR_ASSET',\n",
    " 'TIME_DIFF_MEAN_RATIO_USR_ASSET',\n",
    " #'GAS_PRICE_STD_USR',\n",
    " #'GAS_PRICE_MEDIAN_USR',\n",
    " 'GAS_USED_MEAN_USR',\n",
    " 'GAS_USED_STD_ASSET',\n",
    " 'GAS_USED_STD_USR',\n",
    " #'MIN_INDICATOR',\n",
    " 'GAS_PRICE_USR_ASSET_RATIO_MEAN',\n",
    " #'GAS_USED_LIMIT_RATIO',\n",
    " 'GAS_PRICE_USED_RATIO_MEAN',\n",
    " #'GAS_USED_LIMIT_RATIO_MEAN',\n",
    " #'GAS_PRICE_QUANTILE_RATIO',\n",
    " 'GAS_USED_QUANTILE_RATIO',\n",
    " 'GAS_LIMIT_QUANTILE_RATIO',\n",
    " 'GAS_PRICE_QUANTILE_USR',\n",
    " 'GAS_USED_QUANTILE_USR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData_ = dfData_[l_sfs+['Label', 'Sender ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMOUNT_SUM_USR                                             2877530151.438098\n",
      "AMOUNT_MEAN_ASSET                                            48995742.155142\n",
      "AMOUNT_STD_USR                                              302919513.850023\n",
      "AMOUNT_VAR_USR                                           91760231871134256.0\n",
      "AMOUNT_MIN_ASSET                                                 19788118.17\n",
      "AMOUNT_MIN_USR                                                  238171636.87\n",
      "AMOUNT_MAX_USR                                                   614182955.6\n",
      "TIME_DIFF_MEAN_USR                                               142108354.0\n",
      "TIME_DIFF_STD_USR                                             72917978.79002\n",
      "TIME_DIFF_MEDIAN_USR                                             142108354.0\n",
      "TIME_DIFF_MIN_ASSET                                               18487552.0\n",
      "TIME_DIFF_MIN_USR                                                142108354.0\n",
      "TIME_DIFF_MAX_ASSET                                               71935375.0\n",
      "TIME_DIFF_MAX_USR                                                142108354.0\n",
      "COIN_TYPE_USR_MEAN_ASSET_RATIO                                     326.13666\n",
      "TIME_INTERVL_USR                                                 146874368.0\n",
      "TIME_DIFF_STD_RATIO_USR_ASSET                                   15532.164891\n",
      "TIME_DIFF_MEAN_RATIO_USR_ASSET                                 143622.760461\n",
      "GAS_USED_MEAN_USR                                                 25589676.0\n",
      "GAS_USED_STD_ASSET                                            5332198.684174\n",
      "GAS_USED_STD_USR                                              6506179.330004\n",
      "GAS_PRICE_USR_ASSET_RATIO_MEAN                                    102.541288\n",
      "GAS_PRICE_USED_RATIO_MEAN                                                0.0\n",
      "GAS_USED_QUANTILE_RATIO                                            59.446066\n",
      "GAS_LIMIT_QUANTILE_RATIO                                           65.260604\n",
      "GAS_PRICE_QUANTILE_USR                                              0.000011\n",
      "GAS_USED_QUANTILE_USR                                             25773782.0\n",
      "Label                                                                      1\n",
      "Sender ID                         0xffbd842b9a2f7c901e3a006aab028c932dd9fe2b\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dfData_.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read/process data <a name=\"ReadProcessData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\n",
    "#    'dummy_data/dummy_pipeline_output_data.csv',\n",
    "#    index_col='eid'\n",
    "#)\n",
    "\n",
    "data = dfData_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1681760, 29)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can split the data into features (*X*) and the target column (*y*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_column = 'Label'#fraud_column = 'sim_is_fraud'\n",
    "X = data.drop(\n",
    "    [fraud_column, 'Sender ID'], \n",
    "    axis=1\n",
    ")\n",
    "y = data[fraud_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying any data processing steps, we should split the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=0,\n",
    "    groups = dfData['Sender ID']\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.33, random_state = 0)\n",
    "split = splitter.split(X,y, groups=dfData['Sender ID'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "X_train = X.iloc[train_inds] ; X_test = X.iloc[test_inds]\n",
    "y_train = y.iloc[train_inds] ; y_test = y.iloc[test_inds]\n",
    "\n",
    "#hKFoldSplt = StratifiedGroupKFold(n_splits = numKFolds, shuffle = True, random_state = randomState)\n",
    "#for vTrainIdx, vTestIdx in hKFoldSplt.split(mX, vY, groups = dfData['Sender ID']):\n",
    "#    mXTrain, mXTest, vYTrain, vYTest = mX.iloc[vTrainIdx], mX.iloc[vTestIdx], vY.iloc[vTrainIdx], vY.iloc[vTestIdx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data for rule generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generating new rules, we need to first process the data. The main data processesing steps that need to be applied before using the rule generator are:\n",
    "\n",
    "* Remove uneccessary columns\n",
    "* Impute null values\n",
    "* One hot encode categorical features\n",
    "* Feature selection ***(in this case, the feature set is small, so this step is omitted from the example)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove those columns which will not be useful or make sense to have in our rules - in this case, this includes any features whose name containis 'sim', 'eid' or any high cardinality columns. Note however that there may be additional columns that you have to remove from your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cols = X_train.filter(regex='sim_').columns.tolist()\n",
    "eid_cols = X_train.filter(regex='eid').columns.tolist()\n",
    "high_card_cols = X_train.select_dtypes(include='object').columns[(X_train.select_dtypes(include='object').nunique() > 50)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(sim_cols + eid_cols + high_card_cols, axis=1)\n",
    "X_test = X_test.drop(sim_cols + eid_cols + high_card_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1153340, 27), (528420, 27))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now impute the null values. You can use any imputation method you like - here we'll impute using the following methodology:\n",
    "\n",
    "* Impute numeric values with -1.\n",
    "* Impute categorical features with the category 'missing'.\n",
    "* Impute boolean features with 'missing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in X_train: 3049587\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values in X_train:\", X_train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=object).columns.tolist()\n",
    "bool_cols = X_train.select_dtypes(include=bool).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[bool_cols] = X_train[bool_cols].astype(object)\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[:, num_cols] = X_train.loc[:, num_cols].fillna(-1)\n",
    "X_train.loc[:, cat_cols] = X_train.loc[:, cat_cols].fillna('missing')\n",
    "X_train.loc[:, bool_cols] = X_train.loc[:, bool_cols].fillna('missing')\n",
    "X_test.loc[:, num_cols] = X_test.loc[:, num_cols].fillna(-1)\n",
    "X_test.loc[:, cat_cols] = X_test.loc[:, cat_cols].fillna('missing')\n",
    "X_test.loc[:, bool_cols] = X_test.loc[:, bool_cols].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in X_train: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values in X_train:\", X_train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encode categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can one hot encode the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(use_cat_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    }
   ],
   "source": [
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1153340, 27), (528420, 27))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule generation <a name=\"RuleGeneration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've processed our raw data, we can use this to generate rules. There are two rule generator algorithms in Iguanas:\n",
    "\n",
    "* `RuleGeneratorDT`: Generate rules by extracting the highest performing branches from a tree ensemble model.\n",
    "* `RuleGeneratorOpt`: Generate rules by optimising the thresholds of single features and combining these one condition rules with AND conditions to create more complex rules.\n",
    "\n",
    "**In this example, we'll only use the** `RuleGeneratorDT`**, but you can use the RuleGeneratorOpt instead or additionally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up class parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please see the class docstring for more information on each parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Precision()\n",
    "f1 = FScore(beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metric': f1.fit,\n",
    "    'n_total_conditions': 4,   \n",
    "    'tree_ensemble': RandomForestClassifier(n_estimators=10, random_state=0),\n",
    "    'target_feat_corr_types': 'Infer',\n",
    "    'num_cores': 4,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate class and run fit method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the parameters have been set, we can run the `fit` method to generate the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RuleGeneratorDT(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculating correlation of features with respect to the target ---\n",
      "--- Returning column datatypes ---\n",
      "--- Training tree ensemble ---\n",
      "--- Extracting rules from tree ensemble ---\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "X_rules_gen_train = rg.fit(\n",
    "    X=X_train, \n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method return the binary columns of the generated rules. See the `Attributes` section in the class docstring for a description of each attribute generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGDT_Rule_20221010_0</th>\n",
       "      <th>RGDT_Rule_20221010_1</th>\n",
       "      <th>RGDT_Rule_20221010_2</th>\n",
       "      <th>RGDT_Rule_20221010_3</th>\n",
       "      <th>RGDT_Rule_20221010_4</th>\n",
       "      <th>RGDT_Rule_20221010_5</th>\n",
       "      <th>RGDT_Rule_20221010_6</th>\n",
       "      <th>RGDT_Rule_20221010_7</th>\n",
       "      <th>RGDT_Rule_20221010_8</th>\n",
       "      <th>RGDT_Rule_20221010_9</th>\n",
       "      <th>...</th>\n",
       "      <th>RGDT_Rule_20221010_74</th>\n",
       "      <th>RGDT_Rule_20221010_75</th>\n",
       "      <th>RGDT_Rule_20221010_76</th>\n",
       "      <th>RGDT_Rule_20221010_77</th>\n",
       "      <th>RGDT_Rule_20221010_78</th>\n",
       "      <th>RGDT_Rule_20221010_79</th>\n",
       "      <th>RGDT_Rule_20221010_80</th>\n",
       "      <th>RGDT_Rule_20221010_81</th>\n",
       "      <th>RGDT_Rule_20221010_82</th>\n",
       "      <th>RGDT_Rule_20221010_83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905528</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905526</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905525</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RGDT_Rule_20221010_0  RGDT_Rule_20221010_1  RGDT_Rule_20221010_2  \\\n",
       "905528                     0                     0                     0   \n",
       "905527                     0                     0                     0   \n",
       "905526                     0                     0                     0   \n",
       "905525                     0                     0                     0   \n",
       "905524                     0                     0                     0   \n",
       "\n",
       "        RGDT_Rule_20221010_3  RGDT_Rule_20221010_4  RGDT_Rule_20221010_5  \\\n",
       "905528                     0                     0                     0   \n",
       "905527                     0                     0                     0   \n",
       "905526                     0                     0                     0   \n",
       "905525                     0                     0                     0   \n",
       "905524                     0                     0                     0   \n",
       "\n",
       "        RGDT_Rule_20221010_6  RGDT_Rule_20221010_7  RGDT_Rule_20221010_8  \\\n",
       "905528                     0                     0                     0   \n",
       "905527                     0                     0                     0   \n",
       "905526                     0                     0                     0   \n",
       "905525                     0                     0                     0   \n",
       "905524                     0                     0                     0   \n",
       "\n",
       "        RGDT_Rule_20221010_9  ...  RGDT_Rule_20221010_74  \\\n",
       "905528                     0  ...                      1   \n",
       "905527                     0  ...                      1   \n",
       "905526                     0  ...                      1   \n",
       "905525                     0  ...                      1   \n",
       "905524                     0  ...                      1   \n",
       "\n",
       "        RGDT_Rule_20221010_75  RGDT_Rule_20221010_76  RGDT_Rule_20221010_77  \\\n",
       "905528                      1                      0                      1   \n",
       "905527                      1                      0                      1   \n",
       "905526                      1                      0                      1   \n",
       "905525                      1                      0                      1   \n",
       "905524                      1                      0                      1   \n",
       "\n",
       "        RGDT_Rule_20221010_78  RGDT_Rule_20221010_79  RGDT_Rule_20221010_80  \\\n",
       "905528                      0                      0                      0   \n",
       "905527                      1                      1                      1   \n",
       "905526                      0                      0                      0   \n",
       "905525                      0                      0                      0   \n",
       "905524                      0                      0                      0   \n",
       "\n",
       "        RGDT_Rule_20221010_81  RGDT_Rule_20221010_82  RGDT_Rule_20221010_83  \n",
       "905528                      1                      0                      0  \n",
       "905527                      1                      1                      1  \n",
       "905526                      1                      0                      0  \n",
       "905525                      1                      0                      0  \n",
       "905524                      1                      0                      0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rules_gen_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Optimisation <a name=\"RuleOptimisation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can optimise the existing rules.\n",
    "\n",
    "First, we'll read in the existing rules, which have been stored in the standard Iguanas string format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rule_strings.pkl', 'rb') as f:\n",
    "    rule_strings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then instantiate the `Rules` class with these rules, so that we can convert them into the standard Iguanas lambda expression format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_rules = Rules(rule_strings=rule_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the rules, we use the `as_rule_lambdas` method from the instantiated `Rules` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_rule_lambdas = existing_rules.as_rule_lambdas(as_numpy=False, with_kwargs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard Iguanas lambda expression format allows new values to be injected into the condition string of a rule. This means that the rule's performance can be evaluated with new values (this capability is leveraged in the rule optimisers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `BayesianOptimiser` class to optimise the thresholds of these rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up class parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please see the class docstring for more information on each parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'rule_lambdas': existing_rule_lambdas,\n",
    "    'lambda_kwargs': existing_rules.lambda_kwargs,\n",
    "    'metric': f1.fit,\n",
    "    'n_iter': 10,\n",
    "    'num_cores': 4,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate class and run fit method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the parameters have been set, we can run the `fit` method to optimise the thresholds of the rules.\n",
    "\n",
    "**Note:** we use the raw, unprocessed data here, as productionised rules will usually run on raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = BayesianOptimiser(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking for rules with features that are missing in `X` ---\n",
      "100%|██████████| 23/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Applications\\WPy64-31050\\python-3.10.5.amd64\\lib\\site-packages\\iguanas\\rule_optimisation\\_base_optimiser.py:399: RulesNotOptimisedWarning: Rules `RGDT_Rule137`, `CreateRuleTest2`, `RGDT_Rule81`, `HighFraudTxnPerAccountNum`, `RGDT_Rule256`, `RGDT_Rule35`, `RGDT_Rule193`, `RGDT_Rule241`, `RGDT_Rule263`, `RGDT_Rule313`, `RGDT_Rule195`, `RGDT_Rule153`, `RGDT_Rule112`, `RGDT_Rule2`, `RGDT_Rule65`, `RGDT_Rule45`, `RGDT_Rule162`, `RGDT_Rule272`, `RGDT_Rule24`, `ComplicatedRule`, `Rule2`, `Rule1`, `Rule3` use features that are missing from `X` - unable to optimise or apply these rules\n",
      "  warnings.warn(\n",
      "c:\\Applications\\WPy64-31050\\python-3.10.5.amd64\\lib\\site-packages\\iguanas\\rule_optimisation\\_base_optimiser.py:249: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X = X[rule_features_in_X]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking for rules that exclusively contain non-optimisable conditions ---\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Applications\\WPy64-31050\\python-3.10.5.amd64\\lib\\site-packages\\iguanas\\rule_optimisation\\_base_optimiser.py:374: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X_min = X[cols].min()\n",
      "c:\\Applications\\WPy64-31050\\python-3.10.5.amd64\\lib\\site-packages\\iguanas\\rule_optimisation\\_base_optimiser.py:375: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X_max = X[cols].max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking for rules that exclusively contain zero-variance features ---\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RulesNotOptimisedError",
     "evalue": "There are no optimisable rules in the set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRulesNotOptimisedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [120], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_rules_opt_train \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Applications\\WPy64-31050\\python-3.10.5.amd64\\lib\\site-packages\\iguanas\\rule_optimisation\\bayesian_optimiser.py:189\u001b[0m, in \u001b[0;36mBayesianOptimiser.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    165\u001b[0m         X: PandasDataFrameType,\n\u001b[0;32m    166\u001b[0m         y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    167\u001b[0m         sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PandasDataFrameType:\n\u001b[0;32m    168\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    Optimises a set of rules (given in the standard Iguanas lambda expression\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m    format) using Bayesian Optimisation.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[39m        applicable) rules on the fitted dataset.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m     X_min, X_max, orig_X_rules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_rules_for_opt(\n\u001b[0;32m    190\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    191\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    192\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     \u001b[39m# Generate dictionary of space functions (for optimisation)\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     int_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_int_cols(X\u001b[39m=\u001b[39mX)\n",
      "File \u001b[1;32mc:\\Applications\\WPy64-31050\\python-3.10.5.amd64\\lib\\site-packages\\iguanas\\rule_optimisation\\_base_optimiser.py:288\u001b[0m, in \u001b[0;36m_BaseOptimiser._prepare_rules_for_opt\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimisable_rules, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_optimisable_rules, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzero_variance_rules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_optimisable_rules(\n\u001b[0;32m    283\u001b[0m     rules\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_rules,\n\u001b[0;32m    284\u001b[0m     rule_names_no_opt_conditions\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrule_names_no_opt_conditions,\n\u001b[0;32m    285\u001b[0m     rule_names_zero_var_features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrule_names_zero_var_features\n\u001b[0;32m    286\u001b[0m )\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimisable_rules\u001b[39m.\u001b[39mrule_lambdas:\n\u001b[1;32m--> 288\u001b[0m     \u001b[39mraise\u001b[39;00m RulesNotOptimisedError(\n\u001b[0;32m    289\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThere are no optimisable rules in the set\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    291\u001b[0m \u001b[39m# Get performance of original, optimisable rules\u001b[39;00m\n\u001b[0;32m    292\u001b[0m orig_X_rules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimisable_rules\u001b[39m.\u001b[39mtransform(X\u001b[39m=\u001b[39mX)\n",
      "\u001b[1;31mRulesNotOptimisedError\u001b[0m: There are no optimisable rules in the set"
     ]
    }
   ],
   "source": [
    "X_rules_opt_train = ro.fit(\n",
    "    X=X.loc[X_train.index], \n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method returns the binary columns of the generated rules. See the `Attributes` section in the class docstring for a description of each attribute generated.\n",
    "\n",
    "**Note the following cases where the rule optimiser will be unable to run:**\n",
    "\n",
    "* Rules that contain features that are missing in `X`.\n",
    "* Rules that contain no optimisable features (e.g. all of the conditions are string-based).\n",
    "* Rules that contain exclusively zero variance features.\n",
    "* Rules that contain a feature that is completely null in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_opt_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine rules and remove those which are unnecessary <a name=\"CombineRules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two sets of rules:\n",
    "\n",
    "1. Newly generated rules\n",
    "2. Optimised existing rules\n",
    "\n",
    "We can combine these rule sets, then apply correlation reduction and filtering methods to remove those which are unneccesary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the binary columns of each rule set\n",
    "X_rules_train = pd.concat([\n",
    "    X_rules_gen_train, \n",
    "    X_rules_opt_train\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `SimpleFilter` class from the `rule_selection` module to filter out rules whose performance is below a desired threshold. In this example, we'll filter out rules with an F1 score below 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = SimpleFilter(\n",
    "    threshold=0.01,\n",
    "    operator='>=',\n",
    "    metric=f1.fit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the `fit_transform` method to remove the rules which do not meet the filter requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train = fr.fit_transform(\n",
    "    X_rules=X_rules_train, \n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_transform` method returns a dataframe containing the filtered rule binary columns. See the `Attributes` section in the class docstring for a description of each attribute generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove correlated rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `CorrelatedFilter` class from the `rule_selection` module along with a correlation reduction class to remove correlated rules - see the `correlation_reduction` module for more information on these classes. \n",
    "\n",
    "In this example, we'll be using the `AgglomerativeClusteringReducer` class from that module. To instantiate this class, we also need to define a similarity function - see the `metrics.pairwise` module for more information. In this example, we'll use the Jaccard similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = JaccardSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acfr = AgglomerativeClusteringReducer(\n",
    "    threshold=0.75,\n",
    "    strategy='bottom_up', \n",
    "    similarity_function=js.fit, \n",
    "    metric=f1.fit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate the `CorrelatedFilter` class, and run the `fit_transform` method to remove correlated rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcr = CorrelatedFilter(correlation_reduction_class=acfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train = fcr.fit_transform(\n",
    "    X_rules=X_rules_train,\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_transform` method returns a dataframe containing the binary columns of the uncorrelated rules. See the `Attributes` section in the class docstring for a description of each attribute generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `GreedyFilter` class from the `rule_selection` module to sort the rules by a given metric (e.g. precision), then iterate through the rules and calculate the combined performance of the top n number of rules. Here, we'll sort the rules by precision, then calculate the F1 score of the top n combined rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = GreedyFilter(\n",
    "    metric=f1.fit, \n",
    "    sorting_metric=p.fit,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train = gf.fit_transform(\n",
    "    X_rules=X_rules_train, \n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the combined performance of the top *n* rules (calculated from running the `fit` method) on the training set using the `plot_top_n_performance_on_train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.plot_top_n_performance_on_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows that when the rules are sorted by precision, then the F1 score is calculated for the top n combined rules, the combined performance begins to plateau/drop. So the algorithm will only keep those rules that deliver the maximum combined performance (and drop the rest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_transform` method returns a dataframe containing the filtered rule binary columns. See the `Attributes` section in the class docstring for a description of each attribute generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the RBS Pipeline <a name=\"SetUpPipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up our RBS Pipeline using our combined, filtered rule set. In this case, we'll go for a simple approach:\n",
    "\n",
    "1. If any rules trigger, reject the transaction.\n",
    "2. If no rules trigger, approve any remaining transactions.\n",
    "\n",
    "To set up the pipeline using the logic above, we first need to create the `config` parameter. This is just a list which outlines the stages of the pipeline. Each stage should be defined using a tuple of two elements: \n",
    "\n",
    "1. The first element should be an integer which corresponds to the decision made at that stage (either `0` or `1`).\n",
    "2. The second element should be a list that dictates which rules should trigger for that decision to be made.\n",
    "\n",
    "In our example, the config will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    (1, X_rules_train.columns.tolist())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first stage is configured via the tuple in the first element of the list. This says to apply a decision of `1` (i.e. reject) to transactions where the any of the rules have triggered.\n",
    "\n",
    "We also need to specify the final decision to be made if no rules are triggered - this is set via the `final_decision` parameter. In our case this should be `0`, as we want to approve any remaining transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_decision = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these parameters configured, we can now instantiate our `RBSPipeline` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbsp = RBSPipeline(\n",
    "    config=config,\n",
    "    final_decision=final_decision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise the RBS Pipeline <a name=\"OptimiseThePipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our RBS Pipeline set up, we can optimise it using the RBS Optimiser. Here, we just pass the instatiated pipeline class to the `pipeline` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbso = RBSOptimiser(\n",
    "    pipeline=rbsp, \n",
    "    metric=f1.fit,\n",
    "    n_iter=60, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the `fit_transform` method to optimise the pipeline using the given dataset, then apply it to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_pred_train = rbso.fit_predict(\n",
    "    X_rules=X_rules_train, \n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_transform` method optimises the pipeline and returns the prediction of the optimised pipeline by applying it to the given dataset. See the `Attributes` section in the class docstring for a description of each attribute generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbso.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use Sklearn's *classification_report* and *confusion_matrix* functions to generate some performance metrics for the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=y_train, \n",
    "        y_pred=pipe_pred_train, \n",
    "        digits=4\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(\n",
    "        y_true=y_train, \n",
    "        y_pred=pipe_pred_train\n",
    "    )\n",
    ")\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter rules for the optimised RBS Pipeline <a name=\"FilterRulesForPipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which rules we need for our final, optimised RBS Pipeline, we can filter our original generated and optimised rule sets to include only those rules which are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs_rule_names_gen = [rule for rule in rbso.rules_to_keep if rule in rg.rule_names]\n",
    "rbs_rule_names_opt = [rule for rule in rbso.rules_to_keep if rule in ro.rule_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we filter the original generated and optimised rule sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.filter_rules(include=rbs_rule_names_gen)\n",
    "ro.filter_rules(include=rbs_rule_names_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply the optimised RBS Pipeline to the test set <a name=\"ApplyPipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply our optimised RBS Pipeline to the test set, we first need to apply our filtered generated and optimised rules to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated rules\n",
    "X_rules_gen_test = rg.transform(X=X_test)\n",
    "# Optimised rules (note we using the raw, unprocessed data here)\n",
    "X_rules_opt_test = ro.transform(X=X.loc[X_test.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine these binary columns into one set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_test = pd.concat([\n",
    "    X_rules_gen_test, \n",
    "    X_rules_opt_test\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using these binary columns, apply our optimised RBS Pipeline to the test set, using the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_pipe_pred_test = rbso.predict(X_rules=X_rules_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method returns the prediction of the optimised pipeline by applying it to the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use Sklearn's *classification_report* and *confusion_matrix* functions to generate some performance metrics for the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=y_test, \n",
    "        y_pred=opt_pipe_pred_test, \n",
    "        digits=4\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(\n",
    "        y_true=y_test, \n",
    "        y_pred=opt_pipe_pred_test\n",
    "    )\n",
    ")\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbso.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to initial RBS pipeline performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume that, for our initial RBS pipeline:\n",
    "\n",
    "* Only the **original, existing rules** were used (since these are likely to be the rules that are currently productionised).\n",
    "* The RBS pipeline was set up in a similar way to our optimised RBS Pipeline (i.e. if any rules trigger, reject the transaction; else, approve the transaction).\n",
    "\n",
    "then we can calculate the performance of the initial RBS Pipeline and compare it to our optimised pipeline.\n",
    "\n",
    "To set up the initial RBS Pipeline, we follow a similar process as before. First, we need the names of the **original, existing rules** that are used to reject transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_rule_names = list(existing_rules.rule_strings.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create our `config` using these rule names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    (1, existing_rule_names)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to apply the original, existing rules to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules_existing_test = existing_rules.transform(X=X.loc[X_test.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then instantiate the `RBSPipeline` class using `config` we created above, keeping the other parameters the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbsp_initial = RBSPipeline(\n",
    "    config=config,\n",
    "    final_decision=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the initial RBS pipeline to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pipe_pred_test = rbsp_initial.predict(X_rules=X_rules_existing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compare the performance of the initial RBS Pipeline and the optimised RBS Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "init_pipe_f1 = f1.fit(init_pipe_pred_test, y_test)\n",
    "opt_pipe_f1 = f1.fit(opt_pipe_pred_test, y_test)\n",
    "print(f'The F1 score of the initial RBS Pipeline is: {round(init_pipe_f1, 3)}')\n",
    "print(f'The F1 score of the optimised RBS Pipeline is: {round(opt_pipe_f1, 3)}')\n",
    "print(f'% improvement in F1 score is: {round(100*(opt_pipe_f1-init_pipe_f1)/init_pipe_f1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confusion matrices for initial and optimised pipelines\n",
    "initial_conf_matrix = confusion_matrix(y_true=y_test, y_pred=init_pipe_pred_test)\n",
    "opt_conf_matrix = confusion_matrix(y_true=y_test, y_pred=opt_pipe_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_diff = opt_conf_matrix - initial_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Absolute change in true positives: {conf_matrix_diff[1, 1]}')\n",
    "print(f'Absolute change in false positives: {conf_matrix_diff[0, 1]}')\n",
    "print(f'Absolute change in true negatives: {conf_matrix_diff[0, 0]}')\n",
    "print(f'Absolute change in false negatives: {conf_matrix_diff[1, 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert generated rule conditions to system-ready <a name=\"ConvertGenToSys\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our final rule set and our optimised RBS Pipeline, we can convert the conditions of the generated rules to work on raw, unprocessed data (which is usually the type of data seen in a production system) - this involves the following:\n",
    "\n",
    "* Adding a null condition if the generated condition covered imputed null values.\n",
    "* Converting generated conditions with One Hot Encoded features into conditions that flag that specific category.\n",
    "\n",
    "For example:\n",
    "\n",
    "- If a numeric rule condition initially had a threshold such that the imputed null values were included in the condition, the converted condition has an additional condition to check whether the feature is also null. \n",
    "    - E.g. If a rule initially had the logic `(X['num_items']<=1)` (which included the imputed value of 0), then the converted rule logic would be `((X['num_items']<=1)|(X['num_items'].isna()))`, with an additional condition to check for nulls.\n",
    "- If a categorical rule condition checks whether the value is the imputed null category, the converted condition is such that it will explicitly check for null values. \n",
    "    - E.g. If a rule initially had the logic `(X['country_missing']==True)`, then the converted rule logic would be `(X['country'].isna())`, such that it explicitly checks for null values.\n",
    "- For categorical rule conditions, the converted condition is such that it will explicitly check for the category. \n",
    "    - E.g. If a rule initially had the logic `(X['country_US']==False)`, then the converted rule logic would be `(X['country']!='US')`, such that it explicitly checks whether the 'country' column is not equal to the 'US' category.\n",
    "\n",
    "To do this, we can use the `ConvertProcessedConditionsToGeneral` class from the `iguanas.rules` module. Note that we only need to apply this process to the generated rules, since those are the only rules which reference the processed data.\n",
    "\n",
    "Before we can use this class, we need to provide the following:\n",
    "\n",
    "* A dictionary of the value used to impute nulls for each feature in the original, unprocessed dataset.\n",
    "* A dictionary of the category linked to each One Hot Encoded column.\n",
    "\n",
    "To get these dictionaries, we can use the `ReturnMappings` class from the `iguanas.rules` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ReturnMappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_values_mapping = rm.return_imputed_values_mapping(\n",
    "    [num_cols, -1], \n",
    "    [cat_cols, 'missing'], \n",
    "    [bool_cols, 'missing']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_categories_mapping = rm.return_ohe_categories_mapping(\n",
    "    pre_ohe_cols=X.columns, \n",
    "    post_ohe_cols=X_train.columns, \n",
    "    pre_ohe_dtypes=X.dtypes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our mapping dictionaries for imputed values and one hot encoded values, we can convert the logic of our generated rules to make them production-ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_gen_rules = ConvertProcessedConditionsToGeneral(\n",
    "    imputed_values=imputed_values_mapping, \n",
    "    ohe_categories=ohe_categories_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_gen_rule_strings = conv_gen_rules.convert(\n",
    "    rule_strings=rg.rule_strings, \n",
    "    X=X_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `convert` method returns a dictionary containing the set of rules which account for imputed/OHE variables, defined using the standard Iguanas string format (values) and their names (keys). See the `Attributes` section in the class docstring for a description of each attribute generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our final rule set and RBS Pipeline <a name=\"FinalRuleSet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now (finally!) create the rule set that we'll use in our optimised RBS pipeline. All we need to do is add our generated rules (that were reformatted for raw data) to our optimised rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs_rule_strings = {}\n",
    "rbs_rule_strings.update(conv_gen_rule_strings)\n",
    "rbs_rule_strings.update(ro.rule_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create an instance of the `Rules` class using these rules (we can use this class to change between representations of the rules, if required):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs_rules = Rules(rule_strings=rbs_rule_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our final rules (in the standard Iguanas string format):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs_rules.rule_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our optimised RBS Pipeline configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbso.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "95ddca318bf123e47b38b5a5b9dcba5a0c9d5dde3556722e5a10703c6b4cbfc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
