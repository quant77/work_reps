{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from platform import python_version\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Ensemble Engines\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from DataSetsAuxFun import *\n",
    "#from PredictAssetData import *\n",
    "\n",
    "from joblib import load\n",
    "import pickle\n",
    "import ruamel.yaml#import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'params_no_gas_3.yml') as file:#with open(r'params_no_gas.yml') as file:\n",
    "    params = ruamel.yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = params['seedNum']#512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "# %% Constants\n",
    "\n",
    "DATA_FOLDER_NAME    = 'Validated_Hack_Cases_V1'#params['DATA_FOLDER_NAME'] #'BlockChainAttacksDataSet'\n",
    "DATA_FOLDER_PATTERN = 'DataSet0'#params['DATA_FOLDER_PATTERN']#'DataSet001'\n",
    "DATA_FILE_EXT       = params['DATA_FILE_EXT']#'csv'\n",
    "\n",
    "PROJECT_DIR_NAME    = params['PROJECT_DIR_NAME']# 'CyVers' #<! Royi: Anton, don't change it, it should be a team constant\n",
    "PROJECT_DIR_PATH = os.path.join(os.getcwd()[:os.getcwd().find(PROJECT_DIR_NAME)], PROJECT_DIR_NAME) #>! Pay attention, it will create issues in cases you name the folder `CyVersMe` or anything after / before `CyVers`\n",
    "\n",
    "\n",
    "# We work according to version 0.8 API.\n",
    "# See https://github.com/CyVers-AI/CyVersManagement/blob/main/AiTeamOnBoarding.md.\n",
    "lCsvColName     = params['lCsvColName']\n",
    "lCsvColNameFlag = params['lCsvColNameFlag']\n",
    "\n",
    "lSlctedFeaturesRaw    = params['lSlctedFeaturesRaw']#['Amount', 'Currency', 'Currency Type', 'Amount [USD]', 'Receiver Type', 'Gas Price', 'Gas Limit', 'Gas Used' ]\n",
    "lSlctedFeaturesCalc   = params['lSlctedFeaturesCalc']#[enumObj.name for enumObj in FeatureName if ((enumObj is not FeatureName.TIME_MAX) and (enumObj is not FeatureName.TIME_MIN))]\n",
    "lSlctdFeatures        = lSlctedFeaturesRaw + lSlctedFeaturesCalc\n",
    "lCatFeatures          = params['lCatFeatures']#['Currency', 'Currency Type', 'Receiver Type']#lCatFeatures          = ['Currency', 'Receiver Type']\n",
    "lNumericalFeatures =    [featureName for featureName in lSlctdFeatures if featureName not in lCatFeatures]\n",
    "\n",
    "#lTotalFeatures = lNumericalFeatures + lCatFeatures\n",
    "\n",
    "dataSetRotoDir = os.path.join(PROJECT_DIR_PATH, DATA_FOLDER_NAME)\n",
    "\n",
    "# Training\n",
    "testSetRatio = params['testSetRatio']#1 / 3\n",
    "numKFolds    = params['numKFolds']#3\n",
    "\n",
    "# Amount USD Outlier threshold\n",
    "amountUsdOutlierThr = params['amountUsdOutlierThr']#1e9\n",
    "randomState         = params['randomState'] #42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Loading / Generating Data\n",
    "\n",
    "lCsvFile = ExtractCsvFiles(dataSetRotoDir, folderNamePattern = DATA_FOLDER_PATTERN)\n",
    "print(f'The number of file found: {len(lCsvFile)}')\n",
    "\n",
    "# dfData = pd.read_csv(os.path.join(DATA_FOLDER_NAME, csvFileName))\n",
    "#dfData, dAssetFile = LoadCsvFilesDf(lCsvFile, verifySingleSenderId = False, verifyColumns = False, baseFoldePath = '')\n",
    "dfData, dAssetFile =  LoadCsvFilesDf(lCsvFile, baseFoldePath = '', lColName = lCsvColName, lColFlag =  lCsvColNameFlag)\n",
    "numRows, numCols = dfData.shape\n",
    "\n",
    "print(f\"The number of rows (Samples): {numRows}, The number of columns: {numCols}, number of unique sender id's: {dfData['Sender ID'].unique().shape}\")\n",
    "print(f'The data list of columns is: {dfData.columns} with {len(dfData.columns)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Pre Process Data\n",
    "dfData = PreProcessData(dfData, updateInplace = True, amountUsdOutlierThr = amountUsdOutlierThr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidateData(dfData, lSlctedFeaturesRaw)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Instantiate the Pandas Extension\n",
    "print('Instantiate the Pandas Extension')\n",
    "print(f'The number of assets in the data: {dfData.GrpBySender.numGrps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Calculate Features\n",
    "dfFeatures = ApplyListOfFeatures(dfData, lSlctedFeaturesCalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX , scaler_dct =  GenDataPredict(dfFeatures , lSlctdFeatures , lNumericalFeatures , lCatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lSelectedFeatures_  = lSlctdFeatures\n",
    "if 'Amount [USD]' in lSelectedFeatures_: lSelectedFeatures_[lSelectedFeatures_.index('Amount [USD]')] =  'Amount USD' ### change of 'Amount [USD]' column string for categorical datas in xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_by_files = TrainModelByFiles(dfX , lSelectedFeatures_ , numKFolds, randomState , seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models_by_transacts = TrainModelByTransact(dfX ,lSelectedFeatures_  , lCatFeatures ,lSelectedFeatures_ , numKFolds, randomState )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### saving :\n",
    "xgbModel = models_by_files[-1][2] ### <<--- choose best one by your specific criteria\n",
    "lRawFeatures = lSlctedFeaturesRaw\n",
    "lProcessedFeatures = lSlctedFeaturesCalc\n",
    "lSelectedFeatures = lSlctdFeatures\n",
    "\n",
    "TIME_STAMP_FORMAT = '%Y_%m_%d_%H_%M_%S' #<! For the strftime() formatter\n",
    "MODEL_FILE_NAME = 'Model'\n",
    "MODEL_FILE_EXT  = 'pkl' #<! Used to be JSON for XGBoost, Needs to figure it out\n",
    "\n",
    "folderPostfix   = datetime.datetime.now().strftime(TIME_STAMP_FORMAT)\n",
    "folderName      = MODEL_FILE_NAME + '_' + folderPostfix\n",
    "\n",
    "modelFileName   = MODEL_FILE_NAME + '.' + MODEL_FILE_EXT\n",
    "\n",
    "if not os.path.exists(folderName):\n",
    "    os.mkdir(folderName)\n",
    "\n",
    "pickle.dump(xgbModel, open(os.path.join(folderName, modelFileName), \"wb\"))\n",
    "pickle.dump(lRawFeatures, open(os.path.join(folderName, 'lRawFeatures.pkl'), \"wb\"))\n",
    "pickle.dump(lProcessedFeatures, open(os.path.join(folderName, 'lProcessedFeatures.pkl'), \"wb\"))\n",
    "pickle.dump(lCatFeatures, open(os.path.join(folderName, 'lCatFeatures.pkl'), \"wb\")) \n",
    "pickle.dump(lSelectedFeatures, open(os.path.join(folderName, 'lSelectedFeatures.pkl'), \"wb\"))\n",
    "pickle.dump(scaler_dct, open(os.path.join(folderName, 'scaler_dct.pkl'), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_hash = hashfile(os.path.join(folderName, modelFileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['MODEL_FILE_HASH'] = model_file_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params_no_gas_.yml','w') as yamlfile:\n",
    "        ruamel.yaml.safe_dump(params, yamlfile)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9eec161fd8456093d3a835ffbc5593e17cf1c2afb5c4779c9c15f49ae30927fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
